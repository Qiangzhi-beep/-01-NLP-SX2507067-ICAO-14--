"""
æ–‡ä»¶åï¼šattachment14_enhanced_qa.py
ç‰ˆæœ¬ï¼š2.1ï¼ˆå¢å¼ºç‰ˆï¼‰
æè¿°ï¼šå›½é™…æ°‘èˆªç»„ç»‡é™„ä»¶14ç¬¬Iå·æ™ºèƒ½é—®ç­”ç³»ç»Ÿ - å¢å¼ºç‰ˆ
åŠŸèƒ½ï¼šå¤šè½®å¯¹è¯ã€ç« èŠ‚ç›®å½•æç¤ºã€é•¿ä¸Šä¸‹æ–‡å¤„ç†ã€ç²¾ç¡®å¼•ç”¨ã€è¯„ä¼°åŠŸèƒ½
ä½œè€…ï¼šèˆªç©ºæ³•è§„AIåŠ©æ‰‹
æ—¥æœŸï¼š2024å¹´1æœˆ
"""

import os
import re
import json
import pickle
import numpy as np
from typing import Dict, List, Tuple, Optional, Any, Union
from dataclasses import dataclass, field
from datetime import datetime
import hashlib
from collections import defaultdict, deque
import warnings
warnings.filterwarnings('ignore')

# ==================== å¯¼å…¥å¤–éƒ¨åº“ ====================
try:
    import openai
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    print("è­¦å‘Š: openaiåº“æœªå®‰è£…ï¼ŒAIåŠŸèƒ½å°†å—é™")

try:
    import faiss
    FAISS_AVAILABLE = True
except ImportError:
    FAISS_AVAILABLE = False
    print("è­¦å‘Š: faissåº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€å•æ£€ç´¢")

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False
    print("è­¦å‘Š: sentence-transformersåº“æœªå®‰è£…ï¼Œå°†ä½¿ç”¨ç®€å•å…³é”®è¯æ£€ç´¢")

# ==================== æ•°æ®ç±»å®šä¹‰ ====================

@dataclass
class DocumentChunk:
    """
    æ–‡æ¡£åˆ†å—æ•°æ®ç±»
    ç”¨äºå­˜å‚¨æ‰‹å†Œçš„åˆ†å—å†…å®¹åŠå…¶å…ƒæ•°æ®
    """
    id: str  # å—å”¯ä¸€æ ‡è¯†ç¬¦
    text: str  # å—æ–‡æœ¬å†…å®¹
    metadata: Dict[str, Any] = field(default_factory=dict)  # å…ƒæ•°æ®ï¼ˆç« èŠ‚ã€é¡µç ç­‰ï¼‰
    chapter_path: str = ""  # ç« èŠ‚è·¯å¾„ï¼ˆå¦‚ï¼šç¬¬1ç« >1.1>1.1.1ï¼‰
    embedding: Optional[np.ndarray] = None  # æ–‡æœ¬å‘é‡åµŒå…¥
    tokens: int = 0  # Tokenæ•°é‡

    def __post_init__(self):
        """åˆå§‹åŒ–åè®¡ç®—tokenæ•°é‡"""
        self.tokens = len(self.text.split()) * 1.3  # è¿‘ä¼¼ä¼°è®¡

@dataclass
class ConversationTurn:
    """
    å¯¹è¯è½®æ¬¡æ•°æ®ç±»
    è®°å½•å•è½®å¯¹è¯çš„å®Œæ•´ä¿¡æ¯
    """
    role: str  # "user" æˆ– "assistant"
    content: str  # å¯¹è¯å†…å®¹
    timestamp: datetime = field(default_factory=datetime.now)  # æ—¶é—´æˆ³
    citations: List[Dict] = field(default_factory=list)  # å¼•ç”¨æ¥æº
    confidence: float = 1.0  # ç½®ä¿¡åº¦åˆ†æ•°
    query_used: Optional[str] = None  # å®é™…ä½¿ç”¨çš„æŸ¥è¯¢ï¼ˆç”¨äºè°ƒè¯•ï¼‰
    chapter_suggestions: List[str] = field(default_factory=list)  # ç« èŠ‚ç›®å½•å»ºè®®

@dataclass
class ChapterInfo:
    """
    ç« èŠ‚ä¿¡æ¯æ•°æ®ç±»
    å­˜å‚¨ç« èŠ‚ç»“æ„ä¿¡æ¯
    """
    id: str  # ç« èŠ‚IDï¼ˆå¦‚ï¼š1, 2.1, 3.2.1ï¼‰
    title: str  # ç« èŠ‚æ ‡é¢˜
    level: int  # ç« èŠ‚çº§åˆ«ï¼ˆ1-4ï¼‰
    parent_id: Optional[str] = None  # çˆ¶ç« èŠ‚ID
    content_summary: str = ""  # å†…å®¹æ‘˜è¦
    start_position: int = 0  # åœ¨æ–‡æ¡£ä¸­çš„èµ·å§‹ä½ç½®
    end_position: int = 0  # åœ¨æ–‡æ¡£ä¸­çš„ç»“æŸä½ç½®

@dataclass
class SearchResult:
    """
    æœç´¢ç»“æœæ•°æ®ç±»
    å°è£…æ£€ç´¢åˆ°çš„ç›¸å…³ä¿¡æ¯
    """
    chunk: DocumentChunk  # æ–‡æ¡£å—
    score: float  # ç›¸å…³æ€§åˆ†æ•°
    rank: int  # æ’å

@dataclass
class QAEvaluationMetrics:
    """
    QAç³»ç»Ÿè¯„ä¼°æŒ‡æ ‡æ•°æ®ç±»
    ç”¨äºé‡åŒ–ç³»ç»Ÿæ€§èƒ½
    """
    accuracy: float = 0.0  # å‡†ç¡®æ€§
    citation_f1: float = 0.0  # å¼•ç”¨F1åˆ†æ•°
    hallucination_rate: float = 0.0  # å¹»è§‰ç‡
    response_time: float = 0.0  # å“åº”æ—¶é—´ï¼ˆç§’ï¼‰
    user_satisfaction: float = 0.0  # ç”¨æˆ·æ»¡æ„åº¦

    def to_dict(self) -> Dict:
        """è½¬æ¢ä¸ºå­—å…¸"""
        return {
            'accuracy': self.accuracy,
            'citation_f1': self.citation_f1,
            'hallucination_rate': self.hallucination_rate,
            'response_time': self.response_time,
            'user_satisfaction': self.user_satisfaction
        }

# ==================== ç« èŠ‚ç®¡ç†å™¨ ====================

class ChapterManager:
    """
    ç« èŠ‚ç®¡ç†å™¨ï¼šå¤„ç†æ‰‹å†Œçš„ç« èŠ‚ç»“æ„å’Œç›®å½•
    """

    def __init__(self):
        self.chapters: Dict[str, ChapterInfo] = {}  # æ‰€æœ‰ç« èŠ‚
        self.chapter_tree: Dict[str, List[str]] = defaultdict(list)  # ç« èŠ‚æ ‘ç»“æ„
        self.toc_printed = False  # æ˜¯å¦å·²æ‰“å°ç›®å½•

    def parse_chapters(self, content: str) -> Dict[str, ChapterInfo]:
        """
        è§£ææ–‡æ¡£ä¸­çš„ç« èŠ‚ç»“æ„

        Args:
            content: æ–‡æ¡£å†…å®¹

        Returns:
            ç« èŠ‚ä¿¡æ¯å­—å…¸
        """
        print("ğŸ“š è§£æç« èŠ‚ç›®å½•...")

        # ç« èŠ‚æ ‡é¢˜çš„æ­£åˆ™è¡¨è¾¾å¼
        # æ”¯æŒï¼š## ç¬¬1ç«  æ€»åˆ™, ### 1.1 å®šä¹‰, #### 1.1.1 æŸä¸ªæ¦‚å¿µ
        patterns = [
            (r'^##\s+(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç« [^\n]*)', 1),  # ç« 
            (r'^###\s+(\d+\.\d+[^\n]*)', 2),  # èŠ‚
            (r'^####\s+(\d+\.\d+\.\d+[^\n]*)', 3),  # å°èŠ‚
            (r'^#####\s+(\d+\.\d+\.\d+\.\d+[^\n]*)', 4),  # å°å°èŠ‚
        ]

        lines = content.split('\n')
        current_chapter_id = None
        current_level = 0
        chapter_content = []

        # æŸ¥æ‰¾æ‰€æœ‰ç« èŠ‚æ ‡é¢˜
        for i, line in enumerate(lines):
            for pattern, level in patterns:
                match = re.match(pattern, line.strip())
                if match:
                    title = match.group(1).strip()

                    # æå–ç« èŠ‚ID
                    if level == 1:
                        # ç« ï¼šæå–æ•°å­—
                        chapter_match = re.search(r'ç¬¬([ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+)ç« ', title)
                        if chapter_match:
                            chapter_num = chapter_match.group(1)
                            # ä¸­æ–‡æ•°å­—è½¬é˜¿æ‹‰ä¼¯æ•°å­—
                            cn_to_num = {'ä¸€':1,'äºŒ':2,'ä¸‰':3,'å››':4,'äº”':5,'å…­':6,'ä¸ƒ':7,'å…«':8,'ä¹':9,'å':10}
                            if chapter_num in cn_to_num:
                                chapter_id = str(cn_to_num[chapter_num])
                            else:
                                chapter_id = chapter_num
                        else:
                            chapter_id = str(len(self.chapters) + 1)

                    elif level >= 2:
                        # èŠ‚/å°èŠ‚ï¼šæå–æ•°å­—ç¼–å·
                        num_match = re.search(r'^(\d+(\.\d+)*)', title)
                        if num_match:
                            chapter_id = num_match.group(1)
                        else:
                            chapter_id = f"{current_chapter_id}.{len([c for c in self.chapters.values() if c.parent_id == current_chapter_id]) + 1}"

                    # åˆ›å»ºç« èŠ‚ä¿¡æ¯
                    chapter_info = ChapterInfo(
                        id=chapter_id,
                        title=title,
                        level=level,
                        parent_id=current_chapter_id if level > 1 else None,
                        start_position=i
                    )

                    # ä¿å­˜ç« èŠ‚ä¿¡æ¯
                    self.chapters[chapter_id] = chapter_info

                    # æ„å»ºç« èŠ‚æ ‘
                    if level == 1:
                        self.chapter_tree['root'].append(chapter_id)
                    elif current_chapter_id:
                        self.chapter_tree[current_chapter_id].append(chapter_id)

                    # æ›´æ–°å½“å‰ç« èŠ‚
                    current_chapter_id = chapter_id
                    current_level = level

                    # ç»“æŸä¸Šä¸€ç« çš„å†…å®¹æ”¶é›†
                    if chapter_content and i > 0:
                        prev_chapter_id = list(self.chapters.keys())[-2] if len(self.chapters) > 1 else None
                        if prev_chapter_id and prev_chapter_id in self.chapters:
                            end_pos = i - 1
                            # æ”¶é›†è¯¥ç« èŠ‚çš„å†…å®¹ï¼ˆæœ€å¤š10è¡Œï¼‰
                            content_lines = []
                            for j in range(self.chapters[prev_chapter_id].start_position + 1, min(end_pos, self.chapters[prev_chapter_id].start_position + 11)):
                                if j < len(lines):
                                    content_lines.append(lines[j].strip())

                            summary = ' '.join(content_lines[:5])[:200]
                            if len(summary) >= 200:
                                summary = summary[:197] + "..."
                            self.chapters[prev_chapter_id].content_summary = summary
                            self.chapters[prev_chapter_id].end_position = end_pos

                    chapter_content = []
                    break

        print(f"   è§£æåˆ° {len(self.chapters)} ä¸ªç« èŠ‚")
        return self.chapters

    def get_toc(self, max_level: int = 3) -> str:
        """
        è·å–ç« èŠ‚ç›®å½•

        Args:
            max_level: æœ€å¤§æ˜¾ç¤ºå±‚çº§

        Returns:
            ç›®å½•æ–‡æœ¬
        """
        if not self.chapters:
            return "å°šæœªè§£æç« èŠ‚ç›®å½•"

        toc_lines = ["ğŸ“– ã€Šé™„ä»¶14ç¬¬Iå·ã€‹ç« èŠ‚ç›®å½•", "="*60]

        def build_toc_recursive(parent_id: str, indent: int = 0):
            if parent_id not in self.chapter_tree:
                return

            for chapter_id in sorted(self.chapter_tree[parent_id],
                                   key=lambda x: [int(part) if part.isdigit() else part for part in x.split('.')]):
                if chapter_id in self.chapters:
                    chapter = self.chapters[chapter_id]
                    if chapter.level <= max_level:
                        prefix = "  " * indent
                        if chapter.level == 1:
                            toc_lines.append(f"{prefix}ğŸ“— {chapter.title}")
                        elif chapter.level == 2:
                            toc_lines.append(f"{prefix}  ğŸ“˜ {chapter.title}")
                        elif chapter.level == 3:
                            toc_lines.append(f"{prefix}    ğŸ“™ {chapter.title}")
                        else:
                            toc_lines.append(f"{prefix}      ğŸ““ {chapter.title}")

                        # æ·»åŠ ç®€è¦è¯´æ˜
                        if chapter.content_summary and indent < 2:
                            summary = chapter.content_summary
                            if len(summary) > 80:
                                summary = summary[:77] + "..."
                            toc_lines.append(f"{prefix}      ğŸ’¡ {summary}")

                        build_toc_recursive(chapter_id, indent + 1)

        build_toc_recursive('root')
        toc_lines.append("="*60)
        toc_lines.append("ğŸ’¡ æç¤º: è¾“å…¥ 'æŸ¥çœ‹ç¬¬Xç« ' æˆ– 'ç¬¬Xç« å†…å®¹' è·å–è¯¦ç»†å†…å®¹")

        return "\n".join(toc_lines)

    def get_chapter_content(self, chapter_ref: str, content: str) -> Optional[str]:
        """
        è·å–æŒ‡å®šç« èŠ‚å†…å®¹

        Args:
            chapter_ref: ç« èŠ‚å¼•ç”¨ï¼ˆå¦‚ï¼šç¬¬1ç« ã€2.1ã€3.2.1ï¼‰
            content: æ–‡æ¡£å†…å®¹

        Returns:
            ç« èŠ‚å†…å®¹
        """
        lines = content.split('\n')

        # æŸ¥æ‰¾ç« èŠ‚
        target_chapter = None

        # å°è¯•åŒ¹é…ç« èŠ‚ID
        for chapter_id, chapter in self.chapters.items():
            if chapter_id == chapter_ref or chapter.title == chapter_ref:
                target_chapter = chapter
                break

        # å°è¯•æ¨¡ç³ŠåŒ¹é…
        if not target_chapter:
            for chapter_id, chapter in self.chapters.items():
                if chapter_ref in chapter.title or chapter_ref.replace('ç¬¬', '').replace('ç« ', '') in chapter.title:
                    target_chapter = chapter
                    break

        if not target_chapter:
            return None

        # æå–ç« èŠ‚å†…å®¹
        start_line = target_chapter.start_position
        end_line = target_chapter.end_position if target_chapter.end_position > 0 else start_line + 100

        chapter_lines = []
        in_chapter = False
        current_level = target_chapter.level

        for i in range(start_line, min(end_line, len(lines))):
            line = lines[i].strip()

            # æ£€æŸ¥æ˜¯å¦è¿›å…¥ä¸‹ä¸€ç« èŠ‚
            if i > start_line:
                for pattern, level in [(r'^##', 1), (r'^###', 2), (r'^####', 3), (r'^#####', 4)]:
                    if re.match(pattern, line):
                        if level <= current_level:
                            # é‡åˆ°åŒçº§æˆ–æ›´é«˜çº§æ ‡é¢˜ï¼Œç»“æŸ
                            return '\n'.join(chapter_lines)
                        break

            if line:
                chapter_lines.append(line)

        return '\n'.join(chapter_lines[:200])  # é™åˆ¶é•¿åº¦

    def find_relevant_chapters(self, query: str, top_n: int = 5) -> List[Tuple[str, str, float]]:
        """
        æŸ¥æ‰¾ä¸æŸ¥è¯¢ç›¸å…³çš„ç« èŠ‚

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_n: è¿”å›ç« èŠ‚æ•°é‡

        Returns:
            ç›¸å…³ç« èŠ‚åˆ—è¡¨ï¼ˆç« èŠ‚IDï¼Œæ ‡é¢˜ï¼Œç›¸å…³æ€§åˆ†æ•°ï¼‰
        """
        if not self.chapters:
            return []

        query_lower = query.lower()
        results = []

        for chapter_id, chapter in self.chapters.items():
            score = 0

            # æ ‡é¢˜åŒ¹é…
            if chapter.title:
                title_lower = chapter.title.lower()
                if query_lower in title_lower:
                    score += 5.0

                # éƒ¨åˆ†åŒ¹é…
                query_words = query_lower.split()
                for word in query_words:
                    if len(word) > 2 and word in title_lower:
                        score += 1.0

            # å†…å®¹æ‘˜è¦åŒ¹é…
            if chapter.content_summary:
                summary_lower = chapter.content_summary.lower()
                if query_lower in summary_lower:
                    score += 3.0

            if score > 0:
                results.append((chapter_id, chapter.title, score))

        # æŒ‰åˆ†æ•°æ’åº
        results.sort(key=lambda x: x[2], reverse=True)
        return results[:top_n]

    def print_toc_if_needed(self):
        """å¦‚æœéœ€è¦ï¼Œæ‰“å°ç« èŠ‚ç›®å½•"""
        if not self.toc_printed:
            print("\n" + "="*60)
            print("ğŸ“– æ­£åœ¨ä¸ºæ‚¨åŠ è½½ã€Šé™„ä»¶14ç¬¬Iå·ã€‹ç« èŠ‚ç›®å½•...")
            print("="*60)

            # åªæ‰“å°å‰2çº§çš„ç›®å½•
            toc = self.get_toc(max_level=2)
            print(toc[:1500] + "..." if len(toc) > 1500 else toc)

            self.toc_printed = True

# ==================== æ ¸å¿ƒç³»ç»Ÿç±» ====================

class Attachment14EnhancedQA:
    """
    é™„ä»¶14æ‰‹å†Œå¢å¼ºç‰ˆé—®ç­”ç³»ç»Ÿä¸»ç±»
    åŒ…å«ç« èŠ‚ç›®å½•æç¤ºå’Œå¢å¼ºäº¤äº’åŠŸèƒ½
    """

    def __init__(self,
                 manual_path: str,
                 api_key: str = None,
                 api_base: str = "https://api.siliconflow.cn/v1",
                 model_name: str = "Qwen/Qwen2.5-72B-Instruct",
                 use_embedding: bool = True,
                 show_toc: bool = True):
        """
        åˆå§‹åŒ–é—®ç­”ç³»ç»Ÿ

        Args:
            manual_path: æ‰‹å†Œæ–‡ä»¶è·¯å¾„
            api_key: ç¡…åŸºæµåŠ¨APIå¯†é’¥
            api_base: APIåŸºç¡€URL
            model_name: ä½¿ç”¨çš„æ¨¡å‹åç§°
            use_embedding: æ˜¯å¦ä½¿ç”¨å‘é‡åµŒå…¥
            show_toc: æ˜¯å¦æ˜¾ç¤ºç« èŠ‚ç›®å½•
        """
        print("ğŸš€ åˆå§‹åŒ–é™„ä»¶14å¢å¼ºç‰ˆé—®ç­”ç³»ç»Ÿ...")

        # é…ç½®API
        self.api_key = api_key or "sk-bdgrimfksplnwstzulxfsrdijhjqribunforxvknatzpjlui"
        self.api_base = api_base
        self.model_name = model_name

        # ç³»ç»Ÿé…ç½®
        self.config = self._load_config()
        self.manual_path = manual_path
        self.show_toc = show_toc

        # çŠ¶æ€è·Ÿè¸ª
        self.conversations: Dict[str, List[ConversationTurn]] = defaultdict(list)
        self.evaluation_metrics = QAEvaluationMetrics()
        self.system_stats = {
            'total_queries': 0,
            'successful_answers': 0,
            'rejected_answers': 0,
            'chapter_queries': 0,
            'avg_response_time': 0.0
        }

        # åˆå§‹åŒ–æ ¸å¿ƒç»„ä»¶
        self._initialize_components(use_embedding)

        print("âœ… ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ!")
        print(f"   æ¨¡å‹: {model_name}")
        print(f"   æ£€ç´¢æ¨¡å¼: {'è¯­ä¹‰å‘é‡æ£€ç´¢' if use_embedding else 'å…³é”®è¯æ£€ç´¢'}")
        print(f"   ç« èŠ‚æ•°é‡: {len(self.chapter_manager.chapters)}")
        print(f"   æ–‡æ¡£å—æ•°é‡: {len(self.document_chunks)}")

    def _load_config(self) -> Dict:
        """
        åŠ è½½ç³»ç»Ÿé…ç½®

        Returns:
            é…ç½®å­—å…¸
        """
        return {
            # å¯¹è¯é…ç½®
            'max_history_turns': 10,  # æœ€å¤§å†å²å¯¹è¯è½®æ¬¡
            'max_context_tokens': 32000,  # æœ€å¤§ä¸Šä¸‹æ–‡tokenæ•°
            'summary_threshold': 5,  # è¶…è¿‡æ­¤è½®æ¬¡å¼€å§‹æ‘˜è¦

            # æ£€ç´¢é…ç½®
            'top_k_chunks': 5,  # æ£€ç´¢è¿”å›çš„æ–‡æ¡£å—æ•°é‡
            'similarity_threshold': 0.7,  # ç›¸ä¼¼åº¦é˜ˆå€¼
            'max_chunk_size': 1000,  # æ–‡æ¡£å—æœ€å¤§å­—ç¬¦æ•°
            'chunk_overlap': 100,  # æ–‡æ¡£å—é‡å å­—ç¬¦æ•°

            # å›ç­”ç”Ÿæˆé…ç½®
            'confidence_threshold': 0.7,  # ç½®ä¿¡åº¦é˜ˆå€¼ï¼Œä½äºæ­¤å€¼æ‹’ç»å›ç­”
            'temperature': 0.3,  # ç”Ÿæˆæ¸©åº¦
            'max_tokens': 1500,  # ç”Ÿæˆæœ€å¤§tokenæ•°

            # å¼•ç”¨é…ç½®
            'require_citations': True,  # è¦æ±‚å¼•ç”¨æ¥æº
            'citation_format': "ã€æ¥æº{index}ã€‘",  # å¼•ç”¨æ ¼å¼

            # ç« èŠ‚é…ç½®
            'max_chapter_suggestions': 3,  # æœ€å¤§ç« èŠ‚å»ºè®®æ•°
            'auto_chapter_suggest': True,  # è‡ªåŠ¨æä¾›ç« èŠ‚å»ºè®®

            # è¯„ä¼°é…ç½®
            'enable_evaluation': True,  # å¯ç”¨è¯„ä¼°
            'evaluation_sample_size': 100  # è¯„ä¼°æ ·æœ¬å¤§å°
        }

    def _initialize_components(self, use_embedding: bool):
        """
        åˆå§‹åŒ–ç³»ç»Ÿæ ¸å¿ƒç»„ä»¶

        Args:
            use_embedding: æ˜¯å¦ä½¿ç”¨å‘é‡åµŒå…¥
        """
        # 1. åŠ è½½å¹¶å¤„ç†æ‰‹å†Œ
        print("ğŸ“– åŠ è½½æ‰‹å†Œæ–‡æ¡£...")
        self.manual_content = self._load_manual_content()

        # 2. åˆå§‹åŒ–ç« èŠ‚ç®¡ç†å™¨
        print("ğŸ“š åˆå§‹åŒ–ç« èŠ‚ç®¡ç†å™¨...")
        self.chapter_manager = ChapterManager()
        self.chapter_manager.parse_chapters(self.manual_content)

        # 3. åˆ†å‰²æ–‡æ¡£ä¸ºå—
        print("ğŸ”ª åˆ†å‰²æ–‡æ¡£ä¸ºå—...")
        self.document_chunks = self._split_document_into_chunks()
        print(f"   å…±åˆ†å‰²ä¸º {len(self.document_chunks)} ä¸ªæ–‡æ¡£å—")

        # 4. åˆå§‹åŒ–æ£€ç´¢ç³»ç»Ÿ
        print("ğŸ” åˆå§‹åŒ–æ£€ç´¢ç³»ç»Ÿ...")
        if use_embedding and SENTENCE_TRANSFORMERS_AVAILABLE:
            self.retriever = VectorRetriever(self.document_chunks)
            self.retrieval_mode = "semantic"
        else:
            self.retriever = KeywordRetriever(self.document_chunks)
            self.retrieval_mode = "keyword"

        # 5. åˆå§‹åŒ–å¯¹è¯ç®¡ç†å™¨
        print("ğŸ’¬ åˆå§‹åŒ–å¯¹è¯ç®¡ç†å™¨...")
        self.dialogue_manager = DialogueManager(self.config)

        # 6. åˆå§‹åŒ–AIç”Ÿæˆå™¨
        print("ğŸ¤– åˆå§‹åŒ–AIç”Ÿæˆå™¨...")
        self.ai_generator = AIGenerator(
            api_key=self.api_key,
            api_base=self.api_base,
            model_name=self.model_name,
            config=self.config
        )

        # 7. åˆå§‹åŒ–è¯„ä¼°å™¨ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if self.config['enable_evaluation']:
            print("ğŸ“Š åˆå§‹åŒ–è¯„ä¼°å™¨...")
            self.evaluator = QAEvaluator(self.document_chunks)

        # 8. æ˜¾ç¤ºç« èŠ‚ç›®å½•
        if self.show_toc:
            self.chapter_manager.print_toc_if_needed()

    def _load_manual_content(self) -> str:
        """
        åŠ è½½æ‰‹å†Œå†…å®¹

        Returns:
            æ‰‹å†Œæ–‡æœ¬å†…å®¹
        """
        try:
            with open(self.manual_path, 'r', encoding='utf-8') as f:
                content = f.read()
            print(f"   æˆåŠŸåŠ è½½æ‰‹å†Œï¼Œå¤§å°: {len(content)} å­—ç¬¦")
            return content
        except Exception as e:
            print(f"âŒ åŠ è½½æ‰‹å†Œå¤±è´¥: {e}")
            return ""

    def _split_document_into_chunks(self) -> List[DocumentChunk]:
        """
        å°†æ‰‹å†Œåˆ†å‰²ä¸ºé€‚åˆå¤„ç†çš„æ–‡æ¡£å—

        Returns:
            æ–‡æ¡£å—åˆ—è¡¨
        """
        chunks = []
        chunk_id = 0

        # ä½¿ç”¨ç« èŠ‚ä¿¡æ¯æŒ‡å¯¼åˆ†å‰²
        current_chapter_path = ""
        lines = self.manual_content.split('\n')

        current_chunk_text = ""
        current_metadata = {}

        for i, line in enumerate(lines):
            # æ£€æŸ¥æ˜¯å¦æ˜¯ç« èŠ‚æ ‡é¢˜
            is_chapter_title = False
            chapter_id = None

            for pattern, level in [(r'^##\s+(ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç« [^\n]*)', 1),
                                 (r'^###\s+(\d+\.\d+[^\n]*)', 2),
                                 (r'^####\s+(\d+\.\d+\.\d+[^\n]*)', 3)]:
                match = re.match(pattern, line.strip())
                if match:
                    is_chapter_title = True
                    title = match.group(1).strip()

                    # æŸ¥æ‰¾å¯¹åº”çš„ç« èŠ‚ä¿¡æ¯
                    for cid, chapter in self.chapter_manager.chapters.items():
                        if chapter.title == title:
                            chapter_id = cid
                            # æ„å»ºç« èŠ‚è·¯å¾„
                            if level == 1:
                                current_chapter_path = f"ç¬¬{chapter_id}ç« "
                            elif level == 2:
                                # æŸ¥æ‰¾çˆ¶ç« èŠ‚
                                if chapter.parent_id:
                                    parent_chapter = self.chapter_manager.chapters.get(chapter.parent_id)
                                    if parent_chapter:
                                        current_chapter_path = f"ç¬¬{parent_chapter.id}ç« >{chapter_id}"
                            elif level == 3:
                                # æŸ¥æ‰¾çˆ¶ç« èŠ‚å’Œç¥–çˆ¶ç« èŠ‚
                                if chapter.parent_id:
                                    parent_chapter = self.chapter_manager.chapters.get(chapter.parent_id)
                                    if parent_chapter and parent_chapter.parent_id:
                                        grand_parent = self.chapter_manager.chapters.get(parent_chapter.parent_id)
                                        if grand_parent:
                                            current_chapter_path = f"ç¬¬{grand_parent.id}ç« >{parent_chapter.id}>{chapter_id}"
                            break
                    break

            # å¦‚æœé‡åˆ°ç« èŠ‚æ ‡é¢˜æˆ–å½“å‰å—å·²æ»¡ï¼Œåˆ›å»ºæ–°å—
            if (is_chapter_title and current_chunk_text) or len(current_chunk_text) > self.config['max_chunk_size']:
                if current_chunk_text:
                    chunk = DocumentChunk(
                        id=f"chunk_{chunk_id}",
                        text=current_chunk_text,
                        metadata=current_metadata.copy(),
                        chapter_path=current_chapter_path
                    )
                    chunks.append(chunk)
                    chunk_id += 1
                    current_chunk_text = ""

                # å¦‚æœæ˜¯ç« èŠ‚æ ‡é¢˜ï¼Œå°†å…¶ä½œä¸ºæ–°å—çš„å¼€å§‹
                if is_chapter_title:
                    current_chunk_text = line + "\n"
                    current_metadata = {
                        'chapter_id': chapter_id,
                        'chapter_title': title,
                        'is_chapter_start': True
                    }
            else:
                # æ·»åŠ åˆ°å½“å‰å—
                current_chunk_text += line + "\n"
                if not current_metadata and not is_chapter_title:
                    current_metadata = {'section': 'content'}

        # æ·»åŠ æœ€åä¸€ä¸ªå—
        if current_chunk_text:
            chunk = DocumentChunk(
                id=f"chunk_{chunk_id}",
                text=current_chunk_text,
                metadata=current_metadata.copy(),
                chapter_path=current_chapter_path
            )
            chunks.append(chunk)

        # å¦‚æœä¸Šé¢çš„æ–¹æ³•æ²¡æœ‰å¾—åˆ°è¶³å¤Ÿçš„å—ï¼Œä½¿ç”¨ç®€å•åˆ†å‰²
        if len(chunks) < 10:
            print("   ä½¿ç”¨å¤‡ç”¨åˆ†å‰²æ–¹æ³•...")
            chunks = []
            for i in range(0, len(self.manual_content), self.config['max_chunk_size']):
                chunk_text = self.manual_content[i:i + self.config['max_chunk_size']]
                chunk = DocumentChunk(
                    id=f"chunk_{i//self.config['max_chunk_size']}",
                    text=chunk_text,
                    metadata={'chunk_index': i//self.config['max_chunk_size']},
                    chapter_path=""
                )
                chunks.append(chunk)

        return chunks

    def ask(self,
            question: str,
            session_id: str = "default",
            use_history: bool = True,
            require_citations: bool = True) -> Dict[str, Any]:
        """
        ä¸»é—®ç­”æ¥å£ï¼šå¤„ç†ç”¨æˆ·æé—®å¹¶è¿”å›ç­”æ¡ˆ

        Args:
            question: ç”¨æˆ·é—®é¢˜
            session_id: ä¼šè¯IDï¼ˆç”¨äºå¤šè½®å¯¹è¯ï¼‰
            use_history: æ˜¯å¦ä½¿ç”¨å¯¹è¯å†å²
            require_citations: æ˜¯å¦éœ€è¦å¼•ç”¨æ¥æº

        Returns:
            åŒ…å«ç­”æ¡ˆå’Œå…ƒæ•°æ®çš„å­—å…¸
        """
        import time
        start_time = time.time()
        self.system_stats['total_queries'] += 1

        print(f"\n{'='*60}")
        print(f"ğŸ“ ç”¨æˆ·é—®é¢˜: {question}")
        print(f"ğŸ’¡ ä¼šè¯ID: {session_id}")

        # æ£€æŸ¥æ˜¯å¦æ˜¯ç« èŠ‚ç›®å½•æŸ¥è¯¢
        chapter_response = self._handle_chapter_query(question)
        if chapter_response:
            self.system_stats['chapter_queries'] += 1
            return chapter_response

        # 1. å‡†å¤‡æŸ¥è¯¢ï¼ˆç»“åˆå†å²ï¼‰
        enriched_query = self._prepare_query(question, session_id, use_history)

        # 2. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        search_results = self.retriever.search(
            query=enriched_query,
            top_k=self.config['top_k_chunks']
        )

        # 3. æ£€æŸ¥æ˜¯å¦æœ‰è¶³å¤Ÿç›¸å…³ä¿¡æ¯
        if not search_results or search_results[0].score < self.config['similarity_threshold']:
            response = self._handle_no_relevant_info(question, search_results)
            self.system_stats['rejected_answers'] += 1
            return response

        # 4. å‡†å¤‡ç”Ÿæˆä¸Šä¸‹æ–‡
        context_parts = self._prepare_context_parts(search_results, require_citations)

        # 5. ç”Ÿæˆç­”æ¡ˆ
        ai_response = self.ai_generator.generate_answer(
            question=question,
            context_parts=context_parts,
            conversation_history=self.conversations[session_id][-self.config['max_history_turns']:] if use_history else [],
            require_citations=require_citations
        )

        # 6. è§£æç­”æ¡ˆå¹¶æå–å¼•ç”¨
        parsed_answer = self._parse_ai_response(ai_response, search_results)

        # 7. ç”Ÿæˆç« èŠ‚å»ºè®®
        chapter_suggestions = self._generate_chapter_suggestions(question, parsed_answer)

        # 8. æ›´æ–°å¯¹è¯å†å²
        user_turn = ConversationTurn(
            role="user",
            content=question,
            query_used=enriched_query
        )

        assistant_turn = ConversationTurn(
            role="assistant",
            content=parsed_answer['answer'],
            citations=parsed_answer['citations'],
            confidence=parsed_answer['confidence'],
            chapter_suggestions=chapter_suggestions
        )

        self.conversations[session_id].extend([user_turn, assistant_turn])

        # 9. ç®¡ç†å¯¹è¯å†å²é•¿åº¦ï¼ˆé˜²æ­¢è¿‡é•¿ï¼‰
        self._manage_conversation_length(session_id)

        # 10. è®°å½•å“åº”æ—¶é—´
        response_time = time.time() - start_time
        self.system_stats['avg_response_time'] = (
            self.system_stats['avg_response_time'] * (self.system_stats['total_queries'] - 1) + response_time
        ) / self.system_stats['total_queries']

        # 11. æ„å»ºå“åº”
        response = {
            'answer': parsed_answer['answer'],
            'citations': parsed_answer['citations'],
            'confidence': parsed_answer['confidence'],
            'chapter_suggestions': chapter_suggestions,
            'search_results': [
                {
                    'id': result.chunk.id,
                    'score': float(result.score),
                    'text': result.chunk.text[:200] + "..." if len(result.chunk.text) > 200 else result.chunk.text,
                    'metadata': result.chunk.metadata,
                    'chapter_path': result.chunk.chapter_path
                }
                for result in search_results[:3]
            ],
            'response_time': response_time,
            'session_id': session_id,
            'turn_count': len(self.conversations[session_id]) // 2
        }

        # 12. å¦‚æœå¯ç”¨è¯„ä¼°ï¼Œè®°å½•æ­¤é—®ç­”
        if self.config['enable_evaluation']:
            self.evaluator.record_interaction(question, response)

        self.system_stats['successful_answers'] += 1

        print(f"âœ… ç”Ÿæˆç­”æ¡ˆå®Œæˆ (è€—æ—¶: {response_time:.2f}s)")
        print(f"   ç½®ä¿¡åº¦: {parsed_answer['confidence']:.2%}")
        print(f"   å¼•ç”¨æ•°é‡: {len(parsed_answer['citations'])}")
        if chapter_suggestions:
            print(f"   ç« èŠ‚å»ºè®®: {len(chapter_suggestions)} ä¸ª")

        return response

    def _handle_chapter_query(self, question: str) -> Optional[Dict]:
        """
        å¤„ç†ç« èŠ‚ç›®å½•æŸ¥è¯¢

        Args:
            question: ç”¨æˆ·é—®é¢˜

        Returns:
            å¦‚æœæ˜¯ç« èŠ‚æŸ¥è¯¢è¿”å›å“åº”ï¼Œå¦åˆ™è¿”å›None
        """
        question_lower = question.lower()

        # æ£€æŸ¥æ˜¯å¦æ˜¯ç›®å½•æŸ¥è¯¢
        toc_keywords = ['ç›®å½•', 'ç« èŠ‚', 'ç¬¬å‡ ç« ', 'æœ‰ä»€ä¹ˆç« ', 'toc', 'content', 'ç« èŠ‚åˆ—è¡¨']
        if any(keyword in question_lower for keyword in toc_keywords):
            print("ğŸ“š è¯†åˆ«ä¸ºç« èŠ‚ç›®å½•æŸ¥è¯¢")

            # è·å–è¯¦ç»†ç¨‹åº¦
            detail_level = 2  # é»˜è®¤æ˜¾ç¤º2çº§
            if 'è¯¦ç»†' in question_lower or 'å…¨éƒ¨' in question_lower:
                detail_level = 4
            elif 'ç®€è¦' in question_lower or 'ç®€ç•¥' in question_lower:
                detail_level = 1

            toc = self.chapter_manager.get_toc(max_level=detail_level)

            response = {
                'answer': toc,
                'citations': [],
                'confidence': 1.0,
                'chapter_suggestions': [],
                'search_results': [],
                'response_time': 0.1,
                'session_id': "chapter_query",
                'turn_count': 0,
                'is_chapter_query': True
            }
            return response

        # æ£€æŸ¥æ˜¯å¦æ˜¯å…·ä½“ç« èŠ‚æŸ¥è¯¢
        chapter_patterns = [
            r'ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç« ',
            r'æŸ¥çœ‹ç¬¬[ä¸€äºŒä¸‰å››äº”å…­ä¸ƒå…«ä¹å\d]+ç« ',
            r'ç¬¬\d+ç« å†…å®¹',
            r'\d+\.\d+(\.\d+)*èŠ‚?'
        ]

        for pattern in chapter_patterns:
            matches = re.findall(pattern, question)
            if matches:
                chapter_ref = matches[0].replace('æŸ¥çœ‹', '').replace('å†…å®¹', '').strip()
                print(f"ğŸ“š è¯†åˆ«ä¸ºç« èŠ‚å†…å®¹æŸ¥è¯¢: {chapter_ref}")

                chapter_content = self.chapter_manager.get_chapter_content(chapter_ref, self.manual_content)

                if chapter_content:
                    # æŸ¥æ‰¾å¯¹åº”çš„ç« èŠ‚ä¿¡æ¯
                    chapter_info = None
                    for chapter_id, chapter in self.chapter_manager.chapters.items():
                        if chapter_id in chapter_ref or chapter_ref in chapter.title:
                            chapter_info = chapter
                            break

                    if chapter_info:
                        answer = f"ğŸ“– {chapter_info.title}\n{'='*60}\n{chapter_content[:2000]}"
                        if len(chapter_content) > 2000:
                            answer += f"\n...\nğŸ’¡ å†…å®¹è¿‡é•¿ï¼Œåªæ˜¾ç¤ºå‰2000å­—ç¬¦ã€‚å¦‚éœ€å®Œæ•´å†…å®¹ï¼Œè¯·æŒ‡å®šæ›´å…·ä½“çš„èŠ‚å·ã€‚"
                    else:
                        answer = f"ğŸ“– {chapter_ref}\n{'='*60}\n{chapter_content[:2000]}"

                    response = {
                        'answer': answer,
                        'citations': [],
                        'confidence': 1.0,
                        'chapter_suggestions': [],
                        'search_results': [],
                        'response_time': 0.1,
                        'session_id': "chapter_query",
                        'turn_count': 0,
                        'is_chapter_query': True
                    }
                    return response

        return None

    def _prepare_query(self, question: str, session_id: str, use_history: bool) -> str:
        """
        å‡†å¤‡æ£€ç´¢æŸ¥è¯¢ï¼ˆç»“åˆå¯¹è¯å†å²ï¼‰

        Args:
            question: åŸå§‹é—®é¢˜
            session_id: ä¼šè¯ID
            use_history: æ˜¯å¦ä½¿ç”¨å†å²

        Returns:
            å¢å¼ºåçš„æŸ¥è¯¢
        """
        if not use_history or session_id not in self.conversations:
            return question

        # è·å–æœ€è¿‘çš„å¯¹è¯å†å²
        recent_history = self.conversations[session_id][-self.config['max_history_turns']:]

        if not recent_history:
            return question

        # æå–å†å²ä¸­çš„å…³é”®ä¿¡æ¯
        context_keywords = []
        for turn in recent_history[-3:]:  # åªçœ‹æœ€è¿‘3è½®
            if turn.role == "user":
                # ä»ç”¨æˆ·é—®é¢˜ä¸­æå–åè¯çŸ­è¯­ä½œä¸ºå…³é”®è¯
                nouns = re.findall(r'[\u4e00-\u9fa5]{2,5}è·‘é“|[\u4e00-\u9fa5]{2,5}é“é¢|[\u4e00-\u9fa5]{2,5}ç¯å…‰', turn.content)
                context_keywords.extend(nouns)

        # åˆå¹¶å…³é”®è¯
        if context_keywords:
            enhanced_query = question + " " + " ".join(set(context_keywords))
            print(f"   å¢å¼ºæŸ¥è¯¢: {enhanced_query}")
            return enhanced_query

        return question

    def _prepare_context_parts(self, search_results: List[SearchResult], require_citations: bool) -> List[str]:
        """
        å‡†å¤‡ç”Ÿæˆç­”æ¡ˆçš„ä¸Šä¸‹æ–‡éƒ¨åˆ†

        Args:
            search_results: æ£€ç´¢ç»“æœ
            require_citations: æ˜¯å¦éœ€è¦å¼•ç”¨

        Returns:
            ä¸Šä¸‹æ–‡æ–‡æœ¬åˆ—è¡¨
        """
        context_parts = []

        for i, result in enumerate(search_results):
            chunk = result.chunk
            context_text = f"[æ–‡æ¡£å— {i+1}, ID:{chunk.id}, ç›¸å…³æ€§:{result.score:.3f}"

            if chunk.chapter_path:
                context_text += f", ç« èŠ‚:{chunk.chapter_path}"
            context_text += "]\n"

            if require_citations:
                # æ·»åŠ å¼•ç”¨æ ‡è®°
                context_text += f"ã€æ¥æº{i+1}ã€‘{chunk.text}"
            else:
                context_text += chunk.text

            context_parts.append(context_text)

        return context_parts

    def _parse_ai_response(self, ai_response: Dict, search_results: List[SearchResult]) -> Dict:
        """
        è§£æAIå“åº”ï¼Œæå–ç­”æ¡ˆå’Œå¼•ç”¨

        Args:
            ai_response: AIå“åº”å­—å…¸
            search_results: æ£€ç´¢ç»“æœ

        Returns:
            è§£æåçš„ç­”æ¡ˆå­—å…¸
        """
        answer_text = ai_response.get('content', '')
        confidence = ai_response.get('confidence', 0.8)

        # æå–å¼•ç”¨æ ‡è®°
        citations = []
        citation_pattern = r'ã€æ¥æº(\d+)ã€‘'

        # æŸ¥æ‰¾æ‰€æœ‰å¼•ç”¨æ ‡è®°
        citation_matches = list(re.finditer(citation_pattern, answer_text))

        for match in citation_matches:
            source_index = int(match.group(1)) - 1  # è½¬æ¢ä¸º0-basedç´¢å¼•
            if 0 <= source_index < len(search_results):
                chunk = search_results[source_index].chunk
                citations.append({
                    'source_index': source_index,
                    'chunk_id': chunk.id,
                    'text': chunk.text[:500] + "..." if len(chunk.text) > 500 else chunk.text,
                    'metadata': chunk.metadata,
                    'chapter_path': chunk.chapter_path
                })

        # ç§»é™¤å¼•ç”¨æ ‡è®°ï¼Œä½¿ç­”æ¡ˆæ›´æ˜“è¯»
        clean_answer = re.sub(citation_pattern, '', answer_text).strip()

        return {
            'answer': clean_answer,
            'citations': citations,
            'confidence': confidence,
            'raw_answer': answer_text
        }

    def _generate_chapter_suggestions(self, question: str, parsed_answer: Dict) -> List[str]:
        """
        ç”Ÿæˆç« èŠ‚å»ºè®®

        Args:
            question: ç”¨æˆ·é—®é¢˜
            parsed_answer: è§£æåçš„ç­”æ¡ˆ

        Returns:
            ç« èŠ‚å»ºè®®åˆ—è¡¨
        """
        if not self.config['auto_chapter_suggest']:
            return []

        suggestions = []
        max_suggestions = self.config['max_chapter_suggestions']

        # åŸºäºé—®é¢˜æŸ¥æ‰¾ç›¸å…³ç« èŠ‚
        relevant_chapters = self.chapter_manager.find_relevant_chapters(question, top_n=max_suggestions*2)

        # åŸºäºç­”æ¡ˆä¸­çš„å…³é”®è¯æŸ¥æ‰¾ç›¸å…³ç« èŠ‚
        answer_keywords = re.findall(r'[\u4e00-\u9fa5]{2,6}|[A-Z]{2,}', parsed_answer['answer'])
        for keyword in answer_keywords[:5]:  # å–å‰5ä¸ªå…³é”®è¯
            if len(keyword) > 1:
                keyword_chapters = self.chapter_manager.find_relevant_chapters(keyword, top_n=2)
                relevant_chapters.extend(keyword_chapters)

        # å»é‡å’Œæ’åº
        unique_chapters = {}
        for chapter_id, title, score in relevant_chapters:
            if chapter_id not in unique_chapters or score > unique_chapters[chapter_id][1]:
                unique_chapters[chapter_id] = (title, score)

        # è½¬æ¢ä¸ºåˆ—è¡¨å¹¶æ’åº
        sorted_chapters = sorted(unique_chapters.items(), key=lambda x: x[1][1], reverse=True)

        # ç”Ÿæˆå»ºè®®æ–‡æœ¬
        for i, (chapter_id, (title, score)) in enumerate(sorted_chapters[:max_suggestions]):
            # è·å–ç« èŠ‚ä¿¡æ¯
            chapter_info = self.chapter_manager.chapters.get(chapter_id)
            if chapter_info:
                # æ„å»ºå»ºè®®
                if chapter_info.content_summary:
                    suggestion = f"ğŸ“˜ {title} - {chapter_info.content_summary[:80]}..."
                else:
                    suggestion = f"ğŸ“˜ {title}"

                # æ·»åŠ å¯¼èˆªæç¤º
                if chapter_info.level == 1:
                    suggestion += f" (è¯¦è§ç¬¬{chapter_id}ç« )"
                elif chapter_info.level == 2:
                    parent_chapter = self.chapter_manager.chapters.get(chapter_info.parent_id) if chapter_info.parent_id else None
                    if parent_chapter:
                        suggestion += f" (è¯¦è§ç¬¬{parent_chapter.id}ç« {chapter_id}èŠ‚)"

                suggestions.append(suggestion)

        return suggestions

    def _handle_no_relevant_info(self, question: str, search_results: List[SearchResult]) -> Dict:
        """
        å¤„ç†æ²¡æœ‰ç›¸å…³ä¿¡æ¯çš„æƒ…å†µ

        Args:
            question: ç”¨æˆ·é—®é¢˜
            search_results: æ£€ç´¢ç»“æœï¼ˆå¯èƒ½ä¸ºç©ºï¼‰

        Returns:
            æ‹’ç»å›ç­”çš„å“åº”
        """
        # å°è¯•ä»é—®é¢˜ä¸­æå–å…³é”®è¯ï¼Œæä¾›æ‰‹åŠ¨æœç´¢å»ºè®®
        keywords = re.findall(r'[\u4e00-\u9fa5]{2,6}', question)
        keyword_suggestions = keywords[:3]

        # æŸ¥æ‰¾ç›¸å…³ç« èŠ‚ä½œä¸ºå»ºè®®
        chapter_suggestions = []
        if keyword_suggestions:
            for keyword in keyword_suggestions:
                relevant_chapters = self.chapter_manager.find_relevant_chapters(keyword, top_n=1)
                for chapter_id, title, score in relevant_chapters:
                    if score > 0.5:  # åªæ·»åŠ ç›¸å…³æ€§è¾ƒé«˜çš„ç« èŠ‚
                        chapter_suggestions.append(f"ğŸ“˜ {title}")

        suggestion_text = ""
        if chapter_suggestions:
            suggestion_text = f"\n\nğŸ’¡ ç›¸å…³ç« èŠ‚å»ºè®®:\n" + "\n".join(chapter_suggestions)
        elif keyword_suggestions:
            suggestion_text = f"\n\nğŸ’¡ å»ºè®®æŸ¥é˜…æ‰‹å†Œä¸­å…³äº'{'ã€'.join(keyword_suggestions)}'çš„ç« èŠ‚ã€‚"

        # æä¾›ç« èŠ‚ç›®å½•æç¤º
        toc_hint = "\n\nğŸ“š æ‚¨å¯ä»¥è¾“å…¥'ç›®å½•'æŸ¥çœ‹å®Œæ•´ç« èŠ‚ç›®å½•ï¼Œæˆ–'ç¬¬Xç« 'æŸ¥çœ‹å…·ä½“ç« èŠ‚å†…å®¹ã€‚"

        return {
            'answer': f"æŠ±æ­‰ï¼Œæ ¹æ®ã€Šé™„ä»¶14ã€‹æ‰‹å†Œçš„ç°æœ‰å†…å®¹ï¼Œæˆ‘æ— æ³•æ‰¾åˆ°å…³äºæ­¤é—®é¢˜çš„ç¡®åˆ‡ä¾æ®ã€‚{suggestion_text}{toc_hint}",
            'citations': [],
            'confidence': 0.3,
            'chapter_suggestions': chapter_suggestions,
            'search_results': [],
            'response_time': 0.1,
            'session_id': "rejected",
            'turn_count': 0,
            'is_rejected': True
        }

    def _manage_conversation_length(self, session_id: str):
        """
        ç®¡ç†å¯¹è¯å†å²é•¿åº¦ï¼Œé˜²æ­¢è¿‡é•¿

        Args:
            session_id: ä¼šè¯ID
        """
        max_turns = self.config['max_history_turns'] * 2  # user + assistant å¯¹

        if len(self.conversations[session_id]) > max_turns:
            # ä¿ç•™æœ€è¿‘çš„å¯¹è¯ï¼Œä½†æ€»ç»“æ—©æœŸéƒ¨åˆ†
            old_history = self.conversations[session_id][:-max_turns]
            recent_history = self.conversations[session_id][-max_turns:]

            # åˆ›å»ºæ—©æœŸå†å²çš„æ‘˜è¦
            summary = self._create_conversation_summary(old_history)

            # ç”¨æ‘˜è¦æ›¿æ¢æ—©æœŸå†å²
            summary_turn = ConversationTurn(
                role="system",
                content=f"ã€æ—©æœŸå¯¹è¯æ‘˜è¦ã€‘{summary}",
                citations=[]
            )

            self.conversations[session_id] = [summary_turn] + recent_history

            print(f"   å¯¹è¯å†å²å·²æ‘˜è¦ï¼Œå½“å‰è½®æ¬¡: {len(self.conversations[session_id])}")

    def _create_conversation_summary(self, history: List[ConversationTurn]) -> str:
        """
        åˆ›å»ºå¯¹è¯å†å²æ‘˜è¦

        Args:
            history: å¯¹è¯å†å²

        Returns:
            æ‘˜è¦æ–‡æœ¬
        """
        topics = []
        decisions = []

        for turn in history:
            if turn.role == "user":
                # æå–ä¸»é¢˜
                text_lower = turn.content.lower()
                if any(word in text_lower for word in ['è·‘é“', 'runway']):
                    topics.append('è·‘é“')
                elif any(word in text_lower for word in ['ç¯å…‰', 'light']):
                    topics.append('ç¯å…‰')
                elif any(word in text_lower for word in ['é“é¢', 'pavement']):
                    topics.append('é“é¢')

            if turn.role == "assistant" and turn.confidence > 0.8:
                # æå–é«˜ç½®ä¿¡åº¦çš„ç»“è®º
                if 'å¿…é¡»' in turn.content or 'åº”' in turn.content:
                    # æå–å…³é”®å¥å­
                    sentences = re.split(r'[ã€‚ï¼ï¼Ÿ]', turn.content)
                    for sent in sentences:
                        if len(sent) > 10 and ('å¿…é¡»' in sent or 'åº”' in sent):
                            decisions.append(sent[:100])

        summary_parts = []
        if topics:
            summary_parts.append(f"è®¨è®ºäº†ä»¥ä¸‹ä¸»é¢˜ï¼š{', '.join(set(topics))}")

        if decisions:
            summary_parts.append(f"æ˜ç¡®äº†ä»¥ä¸‹è¦æ±‚ï¼š{'ï¼›'.join(decisions[:3])}")

        return "ï¼›".join(summary_parts) if summary_parts else "æ— é‡è¦ä¿¡æ¯æ‘˜è¦"

    def get_conversation_history(self, session_id: str = "default") -> List[Dict]:
        """
        è·å–å¯¹è¯å†å²

        Args:
            session_id: ä¼šè¯ID

        Returns:
            å¯¹è¯å†å²åˆ—è¡¨
        """
        if session_id not in self.conversations:
            return []

        return [
            {
                'role': turn.role,
                'content': turn.content,
                'time': turn.timestamp.strftime("%H:%M:%S"),
                'citations': turn.citations,
                'confidence': turn.confidence,
                'chapter_suggestions': turn.chapter_suggestions
            }
            for turn in self.conversations[session_id]
        ]

    def get_toc(self, detail_level: int = 2) -> str:
        """
        è·å–ç« èŠ‚ç›®å½•

        Args:
            detail_level: è¯¦ç»†çº§åˆ«ï¼ˆ1-4ï¼‰

        Returns:
            ç›®å½•æ–‡æœ¬
        """
        return self.chapter_manager.get_toc(max_level=detail_level)

    def get_chapter_content(self, chapter_ref: str, max_length: int = 2000) -> Optional[str]:
        """
        è·å–æŒ‡å®šç« èŠ‚å†…å®¹

        Args:
            chapter_ref: ç« èŠ‚å¼•ç”¨ï¼ˆå¦‚ï¼šç¬¬1ç« ã€2.1ã€3.2.1ï¼‰
            max_length: æœ€å¤§è¿”å›é•¿åº¦

        Returns:
            ç« èŠ‚å†…å®¹ï¼ˆæˆªæ–­åˆ°æŒ‡å®šé•¿åº¦ï¼‰
        """
        content = self.chapter_manager.get_chapter_content(chapter_ref, self.manual_content)
        if content and len(content) > max_length:
            content = content[:max_length] + "\n..."
        return content

    def evaluate_system(self, test_questions: List[Dict] = None) -> QAEvaluationMetrics:
        """
        è¯„ä¼°ç³»ç»Ÿæ€§èƒ½

        Args:
            test_questions: æµ‹è¯•é—®é¢˜åˆ—è¡¨

        Returns:
            è¯„ä¼°æŒ‡æ ‡
        """
        if not self.config['enable_evaluation']:
            print("è¯„ä¼°åŠŸèƒ½æœªå¯ç”¨")
            return self.evaluation_metrics

        print("\n" + "="*60)
        print("ğŸ“Š å¼€å§‹ç³»ç»Ÿæ€§èƒ½è¯„ä¼°...")

        # ä½¿ç”¨å†…ç½®æµ‹è¯•é—®é¢˜ï¼ˆå¦‚æœæ²¡æœ‰æä¾›ï¼‰
        if test_questions is None:
            test_questions = self._create_default_test_questions()

        total_questions = len(test_questions)
        print(f"   æµ‹è¯•é—®é¢˜æ•°é‡: {total_questions}")

        # è¿è¡Œæµ‹è¯•
        correct_answers = 0
        total_citations = 0
        correct_citations = 0
        hallucination_count = 0
        total_response_time = 0

        for i, test in enumerate(test_questions, 1):
            question = test['question']
            expected_answer = test.get('expected_answer', '')
            expected_citations = test.get('expected_citations', [])

            print(f"\n   [{i}/{total_questions}] æµ‹è¯•é—®é¢˜: {question}")

            # è·å–ç³»ç»Ÿç­”æ¡ˆ
            response = self.ask(question, session_id=f"test_{i}", use_history=False)

            # è¯„ä¼°å‡†ç¡®æ€§
            is_correct = self.evaluator.evaluate_accuracy(
                response['answer'],
                expected_answer
            )

            if is_correct:
                correct_answers += 1

            # è¯„ä¼°å¼•ç”¨
            citation_metrics = self.evaluator.evaluate_citations(
                response['citations'],
                expected_citations
            )
            total_citations += citation_metrics['total_expected']
            correct_citations += citation_metrics['correct']

            # æ£€æŸ¥å¹»è§‰
            if self.evaluator.detect_hallucination(response['answer'], response['citations']):
                hallucination_count += 1

            total_response_time += response['response_time']

        # è®¡ç®—æŒ‡æ ‡
        accuracy = correct_answers / total_questions if total_questions > 0 else 0

        precision = correct_citations / (correct_citations + (total_citations - correct_citations)) if total_citations > 0 else 0
        recall = correct_citations / total_citations if total_citations > 0 else 0
        citation_f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

        hallucination_rate = hallucination_count / total_questions if total_questions > 0 else 0
        avg_response_time = total_response_time / total_questions if total_questions > 0 else 0

        # æ›´æ–°è¯„ä¼°æŒ‡æ ‡
        self.evaluation_metrics.accuracy = accuracy
        self.evaluation_metrics.citation_f1 = citation_f1
        self.evaluation_metrics.hallucination_rate = hallucination_rate
        self.evaluation_metrics.response_time = avg_response_time

        print("\n" + "="*60)
        print("ğŸ“ˆ è¯„ä¼°ç»“æœ:")
        print(f"   å‡†ç¡®æ€§: {accuracy:.2%}")
        print(f"   å¼•ç”¨F1åˆ†æ•°: {citation_f1:.3f}")
        print(f"   å¹»è§‰ç‡: {hallucination_rate:.2%}")
        print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_response_time:.2f}ç§’")
        print("="*60)

        return self.evaluation_metrics

    def _create_default_test_questions(self) -> List[Dict]:
        """
        åˆ›å»ºé»˜è®¤æµ‹è¯•é—®é¢˜

        Returns:
            æµ‹è¯•é—®é¢˜åˆ—è¡¨
        """
        return [
            {
                'question': 'ä»€ä¹ˆæ˜¯è·‘é“ç«¯å®‰å…¨åŒºï¼Ÿ',
                'expected_answer': 'è·‘é“ç«¯å®‰å…¨åŒºæ˜¯ä¸å‡é™å¸¦ç«¯ç›¸é‚»çš„ä¸€å—åŒºåŸŸ',
                'expected_citations': ['è·‘é“ç«¯å®‰å…¨åŒº', 'RESA']
            },
            {
                'question': 'PCNæ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ',
                'expected_answer': 'é“é¢ç­‰çº§å·ï¼Œè¡¨ç¤ºé“é¢æ‰¿è½½å¼ºåº¦çš„ç¼–å·',
                'expected_citations': ['PCN', 'é“é¢ç­‰çº§å·']
            },
            {
                'question': 'è·‘é“çš„æœ€å°å®½åº¦æ˜¯å¤šå°‘ï¼Ÿ',
                'expected_answer': 'æ ¹æ®åŸºå‡†ä»£ç å’Œå¤–ä¾§ä¸»èµ·è½æ¶è½®è·ç¡®å®š',
                'expected_citations': ['è·‘é“å®½åº¦', 'æœ€å°å®½åº¦']
            },
            {
                'question': 'ç›®å½•',
                'expected_answer': 'ç« èŠ‚ç›®å½•',
                'expected_citations': []
            }
        ]

    def get_system_stats(self) -> Dict:
        """
        è·å–ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç³»ç»Ÿç»Ÿè®¡å­—å…¸
        """
        return {
            'total_queries': self.system_stats['total_queries'],
            'successful_answers': self.system_stats['successful_answers'],
            'rejected_answers': self.system_stats['rejected_answers'],
            'chapter_queries': self.system_stats['chapter_queries'],
            'success_rate': self.system_stats['successful_answers'] / self.system_stats['total_queries'] if self.system_stats['total_queries'] > 0 else 0,
            'avg_response_time': self.system_stats['avg_response_time'],
            'active_sessions': len(self.conversations),
            'retrieval_mode': self.retrieval_mode,
            'total_chapters': len(self.chapter_manager.chapters)
        }

    def clear_conversation(self, session_id: str = "default"):
        """
        æ¸…é™¤æŒ‡å®šä¼šè¯çš„å†å²

        Args:
            session_id: ä¼šè¯ID
        """
        if session_id in self.conversations:
            self.conversations[session_id].clear()
            print(f"ğŸ—‘ï¸  å·²æ¸…é™¤ä¼šè¯ {session_id} çš„å†å²è®°å½•")

# ==================== æ£€ç´¢å™¨åŸºç±»ä¸å®ç° ====================

class BaseRetriever:
    """æ£€ç´¢å™¨åŸºç±»"""

    def __init__(self, chunks: List[DocumentChunk]):
        self.chunks = chunks

    def search(self, query: str, top_k: int = 5) -> List[SearchResult]:
        """æœç´¢ç›¸å…³æ–‡æ¡£å—ï¼ˆéœ€å­ç±»å®ç°ï¼‰"""
        raise NotImplementedError

class KeywordRetriever(BaseRetriever):
    """å…³é”®è¯æ£€ç´¢å™¨ï¼ˆç®€å•å®ç°ï¼‰"""

    def search(self, query: str, top_k: int = 5) -> List[SearchResult]:
        """
        åŸºäºå…³é”®è¯åŒ¹é…çš„æ£€ç´¢

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        results = []
        query_terms = set(re.findall(r'[\u4e00-\u9fa5]{2,6}|[A-Z]{2,}', query))

        for chunk in self.chunks:
            score = 0
            chunk_text = chunk.text

            for term in query_terms:
                if term in chunk_text:
                    score += 1
                    # å¢åŠ ç²¾ç¡®åŒ¹é…çš„æƒé‡
                    if f" {term} " in f" {chunk_text} ":
                        score += 0.5

            # å½’ä¸€åŒ–åˆ†æ•°
            if query_terms:
                score = score / (len(query_terms) * 1.5)

            if score > 0:
                results.append(SearchResult(chunk=chunk, score=min(score, 1.0), rank=len(results)))

        # æŒ‰åˆ†æ•°æ’åº
        results.sort(key=lambda x: x.score, reverse=True)

        return results[:top_k]

class VectorRetriever(BaseRetriever):
    """å‘é‡æ£€ç´¢å™¨ï¼ˆåŸºäºè¯­ä¹‰ç›¸ä¼¼åº¦ï¼‰"""

    def __init__(self, chunks: List[DocumentChunk], model_name: str = 'paraphrase-multilingual-MiniLM-L12-v2'):
        super().__init__(chunks)

        if not SENTENCE_TRANSFORMERS_AVAILABLE:
            print("âš ï¸  sentence-transformersä¸å¯ç”¨ï¼Œå›é€€åˆ°å…³é”®è¯æ£€ç´¢")
            self.use_vector = False
            return

        print(f"   åŠ è½½åµŒå…¥æ¨¡å‹: {model_name}")
        self.embedding_model = SentenceTransformer(model_name)
        self.use_vector = True

        # ä¸ºæ‰€æœ‰å—ç”ŸæˆåµŒå…¥
        self._generate_embeddings()

        # åˆ›å»ºFAISSç´¢å¼•ï¼ˆå¦‚æœå¯ç”¨ï¼‰
        if FAISS_AVAILABLE:
            self._create_faiss_index()

    def _generate_embeddings(self):
        """ä¸ºæ‰€æœ‰æ–‡æ¡£å—ç”Ÿæˆå‘é‡åµŒå…¥"""
        print("   ç”Ÿæˆæ–‡æ¡£å—åµŒå…¥...")
        texts = [chunk.text for chunk in self.chunks]

        # æ‰¹é‡ç”ŸæˆåµŒå…¥ï¼ˆæé«˜æ•ˆç‡ï¼‰
        batch_size = 32
        all_embeddings = []

        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i+batch_size]
            batch_embeddings = self.embedding_model.encode(batch_texts, show_progress_bar=False)
            all_embeddings.append(batch_embeddings)

        # åˆå¹¶æ‰€æœ‰åµŒå…¥
        embeddings = np.vstack(all_embeddings)

        # åˆ†é…ç»™æ–‡æ¡£å—
        for i, chunk in enumerate(self.chunks):
            chunk.embedding = embeddings[i]

    def _create_faiss_index(self):
        """åˆ›å»ºFAISSå‘é‡ç´¢å¼•"""
        print("   åˆ›å»ºFAISSå‘é‡ç´¢å¼•...")

        # æ”¶é›†æ‰€æœ‰åµŒå…¥
        embeddings = []
        valid_chunks = []

        for chunk in self.chunks:
            if chunk.embedding is not None:
                embeddings.append(chunk.embedding)
                valid_chunks.append(chunk)

        if not embeddings:
            print("âš ï¸  æ— æœ‰æ•ˆåµŒå…¥ï¼Œæ— æ³•åˆ›å»ºFAISSç´¢å¼•")
            return

        embeddings = np.array(embeddings).astype('float32')
        dimension = embeddings.shape[1]

        # åˆ›å»ºç´¢å¼•
        self.faiss_index = faiss.IndexFlatIP(dimension)  # å†…ç§¯ç›¸ä¼¼åº¦
        self.faiss_index.add(embeddings)
        self.indexed_chunks = valid_chunks

        print(f"   FAISSç´¢å¼•åˆ›å»ºå®Œæˆï¼Œç»´åº¦: {dimension}, æ–‡æ¡£æ•°: {len(valid_chunks)}")

    def search(self, query: str, top_k: int = 5) -> List[SearchResult]:
        """
        åŸºäºå‘é‡ç›¸ä¼¼åº¦çš„æ£€ç´¢

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡

        Returns:
            æœç´¢ç»“æœåˆ—è¡¨
        """
        if not self.use_vector:
            # å›é€€åˆ°å…³é”®è¯æ£€ç´¢
            simple_retriever = KeywordRetriever(self.chunks)
            return simple_retriever.search(query, top_k)

        # ç”ŸæˆæŸ¥è¯¢å‘é‡
        query_embedding = self.embedding_model.encode([query])[0].reshape(1, -1).astype('float32')

        if FAISS_AVAILABLE and hasattr(self, 'faiss_index'):
            # ä½¿ç”¨FAISSæœç´¢
            scores, indices = self.faiss_index.search(query_embedding, min(top_k * 2, len(self.indexed_chunks)))

            results = []
            for score, idx in zip(scores[0], indices[0]):
                if idx >= 0 and score > 0:
                    chunk = self.indexed_chunks[idx]
                    # å½’ä¸€åŒ–åˆ†æ•°ï¼ˆå†…ç§¯ç›¸ä¼¼åº¦å¯èƒ½åœ¨0-1ä¹‹é—´ï¼‰
                    normalized_score = min(float(score), 1.0)
                    results.append(SearchResult(chunk=chunk, score=normalized_score, rank=len(results)))

            return results[:top_k]
        else:
            # ä½¿ç”¨ç®€å•å‘é‡ç›¸ä¼¼åº¦è®¡ç®—
            results = []

            for chunk in self.chunks:
                if chunk.embedding is not None:
                    # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
                    similarity = np.dot(query_embedding[0], chunk.embedding) / (
                        np.linalg.norm(query_embedding[0]) * np.linalg.norm(chunk.embedding) + 1e-10
                    )

                    if similarity > 0:
                        results.append(SearchResult(chunk=chunk, score=float(similarity), rank=len(results)))

            # æŒ‰ç›¸ä¼¼åº¦æ’åº
            results.sort(key=lambda x: x.score, reverse=True)

            return results[:top_k]

# ==================== å¯¹è¯ç®¡ç†å™¨ ====================

class DialogueManager:
    """å¯¹è¯ç®¡ç†å™¨ï¼šå¤„ç†å¤šè½®å¯¹è¯é€»è¾‘"""

    def __init__(self, config: Dict):
        self.config = config
        self.conversation_states = {}

    def update_context(self, session_id: str, user_query: str, system_response: str):
        """
        æ›´æ–°å¯¹è¯ä¸Šä¸‹æ–‡

        Args:
            session_id: ä¼šè¯ID
            user_query: ç”¨æˆ·æŸ¥è¯¢
            system_response: ç³»ç»Ÿå“åº”
        """
        if session_id not in self.conversation_states:
            self.conversation_states[session_id] = {
                'history': [],
                'topic': None,
                'question_count': 0,
                'chapter_references': []  # å¼•ç”¨çš„ç« èŠ‚
            }

        state = self.conversation_states[session_id]
        state['history'].append({
            'user': user_query,
            'system': system_response,
            'timestamp': datetime.now()
        })
        state['question_count'] += 1

        # é™åˆ¶å†å²é•¿åº¦
        max_history = self.config.get('max_history_turns', 10)
        if len(state['history']) > max_history:
            state['history'] = state['history'][-max_history:]

        # æ›´æ–°å½“å‰ä¸»é¢˜
        self._update_topic(session_id, user_query)

    def _update_topic(self, session_id: str, query: str):
        """
        æ›´æ–°å¯¹è¯ä¸»é¢˜

        Args:
            session_id: ä¼šè¯ID
            query: ç”¨æˆ·æŸ¥è¯¢
        """
        state = self.conversation_states[session_id]

        # ä»æŸ¥è¯¢ä¸­æå–å¯èƒ½çš„ä¸»é¢˜
        topic_keywords = {
            'è·‘é“': ['è·‘é“', 'runway', 'å‡é™å¸¦', 'è·‘é“ç«¯'],
            'ç¯å…‰': ['ç¯å…‰', 'light', 'ç›®è§†', 'è¿›è¿‘ç¯'],
            'é“é¢': ['é“é¢', 'pavement', 'PCN', 'ACN'],
            'éšœç¢ç‰©': ['éšœç¢ç‰©', 'obstacle', 'é™åˆ¶é¢'],
            'æ ‡å¿—': ['æ ‡å¿—', 'marking', 'æ ‡è®°'],
            'ç« èŠ‚': ['ç›®å½•', 'ç¬¬å‡ ç« ', 'ç« èŠ‚', 'toc']
        }

        for topic, keywords in topic_keywords.items():
            if any(keyword in query for keyword in keywords):
                state['topic'] = topic
                break

    def get_conversation_summary(self, session_id: str) -> str:
        """
        è·å–å¯¹è¯æ‘˜è¦

        Args:
            session_id: ä¼šè¯ID

        Returns:
            å¯¹è¯æ‘˜è¦
        """
        if session_id not in self.conversation_states:
            return "æ— å¯¹è¯å†å²"

        state = self.conversation_states[session_id]

        if not state['history']:
            return "å¯¹è¯åˆšåˆšå¼€å§‹"

        # æå–å…³é”®ä¿¡æ¯
        topics = []
        questions = []

        for turn in state['history'][-3:]:  # æœ€è¿‘3è½®
            if 'user' in turn:
                user_q = turn['user']
                # ç®€å•æå–
                if len(user_q) > 5:
                    questions.append(user_q[:50] + "...")

        summary = f"å¯¹è¯ä¸»é¢˜: {state['topic'] or 'æœªæŒ‡å®š'}, é—®é¢˜æ•°é‡: {state['question_count']}"
        if questions:
            summary += f", æœ€è¿‘é—®é¢˜: {'; '.join(questions)}"

        return summary

# ==================== AIç”Ÿæˆå™¨ ====================

class AIGenerator:
    """AIç­”æ¡ˆç”Ÿæˆå™¨ï¼šè°ƒç”¨å¤§æ¨¡å‹ç”Ÿæˆç­”æ¡ˆ"""

    def __init__(self, api_key: str, api_base: str, model_name: str, config: Dict):
        self.api_key = api_key
        self.api_base = api_base
        self.model_name = model_name
        self.config = config

        # é…ç½®OpenAIå®¢æˆ·ç«¯
        if OPENAI_AVAILABLE:
            openai.api_key = self.api_key
            openai.api_base = self.api_base
        else:
            print("âš ï¸  OpenAIåº“ä¸å¯ç”¨ï¼ŒAIç”ŸæˆåŠŸèƒ½å—é™")

    def generate_answer(self,
                       question: str,
                       context_parts: List[str],
                       conversation_history: List[ConversationTurn] = None,
                       require_citations: bool = True) -> Dict[str, Any]:
        """
        ç”Ÿæˆç­”æ¡ˆ

        Args:
            question: ç”¨æˆ·é—®é¢˜
            context_parts: ä¸Šä¸‹æ–‡æ–‡æœ¬åˆ—è¡¨
            conversation_history: å¯¹è¯å†å²
            require_citations: æ˜¯å¦éœ€è¦å¼•ç”¨

        Returns:
            ç”Ÿæˆçš„ç­”æ¡ˆå­—å…¸
        """
        # æ„å»ºæç¤ºè¯
        prompt = self._build_prompt(
            question,
            context_parts,
            conversation_history,
            require_citations
        )

        # æ£€æŸ¥tokené•¿åº¦
        estimated_tokens = len(prompt.split()) * 1.3

        if estimated_tokens > self.config['max_context_tokens']:
            print(f"âš ï¸  æç¤ºè¯è¿‡é•¿ ({estimated_tokens:.0f} tokens)ï¼Œè¿›è¡Œå‹ç¼©...")
            prompt = self._compress_prompt(prompt, context_parts)

        # è°ƒç”¨API
        response = self._call_api(prompt)

        # è§£æå“åº”
        if isinstance(response, str):
            content = response
            confidence = self._estimate_confidence(content, context_parts)
        elif isinstance(response, dict):
            content = response.get('choices', [{}])[0].get('message', {}).get('content', '')
            confidence = response.get('confidence', 0.8)
        else:
            content = "æŠ±æ­‰ï¼Œç”Ÿæˆç­”æ¡ˆæ—¶å‡ºç°é”™è¯¯ã€‚"
            confidence = 0.3

        return {
            'content': content,
            'confidence': confidence,
            'prompt_tokens': estimated_tokens
        }

    def _build_prompt(self,
                     question: str,
                     context_parts: List[str],
                     conversation_history: List[ConversationTurn],
                     require_citations: bool) -> str:
        """
        æ„å»ºæç¤ºè¯

        Args:
            question: ç”¨æˆ·é—®é¢˜
            context_parts: ä¸Šä¸‹æ–‡æ–‡æœ¬åˆ—è¡¨
            conversation_history: å¯¹è¯å†å²
            require_citations: æ˜¯å¦éœ€è¦å¼•ç”¨

        Returns:
            å®Œæ•´çš„æç¤ºè¯
        """
        # ç³»ç»ŸæŒ‡ä»¤
        system_instruction = """ä½ æ˜¯ä¸€åä¸¥è°¨çš„å›½é™…æ°‘èˆªç»„ç»‡é™„ä»¶14ä¸“å®¶ã€‚è¯·ä¸¥æ ¼æ ¹æ®æä¾›çš„ã€Šé™„ä»¶14ç¬¬Iå·ï¼šæœºåœºè®¾è®¡ä¸è¿è¡Œã€‹åŸæ–‡å›ç­”é—®é¢˜ã€‚

å¿…é¡»éµå®ˆä»¥ä¸‹è§„åˆ™ï¼š
1. ç­”æ¡ˆå¿…é¡»å®Œå…¨åŸºäºæä¾›çš„ä¸Šä¸‹æ–‡ï¼Œä¸å¾—æ·»åŠ ä»»ä½•å¤–éƒ¨çŸ¥è¯†æˆ–ä¸ªäººè§‚ç‚¹ã€‚
2. å¦‚æœä¸Šä¸‹æ–‡æ²¡æœ‰ç›¸å…³ä¿¡æ¯ï¼Œå¿…é¡»æ˜ç¡®å›ç­”"æ ¹æ®æä¾›çš„èµ„æ–™æ— æ³•å›ç­”æ­¤é—®é¢˜"ã€‚
3. ä¿æŒä¸“ä¸šã€å‡†ç¡®ï¼Œä½¿ç”¨è§„èŒƒçš„èˆªç©ºæœ¯è¯­ã€‚
4. ç­”æ¡ˆåº”ç®€æ´æ˜äº†ï¼Œä½†éœ€åŒ…å«å¿…è¦çš„æŠ€æœ¯ç»†èŠ‚ã€‚
"""

        if require_citations:
            system_instruction += """5. å¯¹äºæ¯ä¸ªå…³é”®äº‹å®ã€æ•°æ®æˆ–æ ‡å‡†ï¼Œå¿…é¡»åœ¨ç­”æ¡ˆä¸­æ ‡æ³¨æ¥æºï¼Œä½¿ç”¨æ ¼å¼ã€æ¥æºXã€‘ï¼Œå…¶ä¸­Xå¯¹åº”ä¸Šä¸‹æ–‡ä¸­çš„æ–‡æ¡£å—ç¼–å·ã€‚
6. åœ¨ç­”æ¡ˆæœ«å°¾ï¼Œä»¥"å¼•ç”¨æ¥æºï¼š"å¼€å¤´åˆ—å‡ºæ‰€æœ‰å¼•ç”¨çš„æ–‡æ¡£å—æ‘˜è¦ã€‚"""

        # æ·»åŠ ä¸Šä¸‹æ–‡
        context_text = "\n\n".join(context_parts)

        # æ·»åŠ å¯¹è¯å†å²ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
        history_text = ""
        if conversation_history and len(conversation_history) > 0:
            history_text = "\n\nã€å¯¹è¯å†å²ã€‘\n"
            for turn in conversation_history[-3:]:  # æœ€è¿‘3è½®
                if turn.role == "user":
                    history_text += f"ç”¨æˆ·: {turn.content}\n"
                elif turn.role == "assistant":
                    history_text += f"åŠ©æ‰‹: {turn.content[:100]}...\n"

        # æ„å»ºå®Œæ•´æç¤ºè¯
        prompt = f"""{system_instruction}

{history_text}

ã€ç›¸å…³ä¸Šä¸‹æ–‡ã€‘
{context_text}

ã€å½“å‰é—®é¢˜ã€‘
{question}

è¯·ç”Ÿæˆä¸“ä¸šçš„ç­”æ¡ˆï¼š"""

        return prompt

    def _compress_prompt(self, prompt: str, context_parts: List[str]) -> str:
        """
        å‹ç¼©æç¤ºè¯ï¼ˆå½“è¶…è¿‡tokené™åˆ¶æ—¶ï¼‰

        Args:
            prompt: åŸå§‹æç¤ºè¯
            context_parts: ä¸Šä¸‹æ–‡æ–‡æœ¬åˆ—è¡¨

        Returns:
            å‹ç¼©åçš„æç¤ºè¯
        """
        # ç®€åŒ–ä¸Šä¸‹æ–‡ï¼šåªä¿ç•™æ¯ä¸ªå—çš„å‰200å­—ç¬¦
        compressed_context = []
        for i, part in enumerate(context_parts):
            # æå–å—çš„å‰éƒ¨åˆ†
            lines = part.split('\n')
            if lines:
                first_line = lines[0]
                if len(first_line) > 200:
                    compressed_part = first_line[:200] + "..."
                else:
                    compressed_part = part[:300] + "..." if len(part) > 300 else part

                compressed_context.append(compressed_part)

        # é‡æ–°æ„å»ºæç¤ºè¯
        system_part = prompt.split("ã€ç›¸å…³ä¸Šä¸‹æ–‡ã€‘")[0]
        question_part = "ã€å½“å‰é—®é¢˜ã€‘" + prompt.split("ã€å½“å‰é—®é¢˜ã€‘")[1] if "ã€å½“å‰é—®é¢˜ã€‘" in prompt else ""

        compressed_prompt = f"{system_part}\n\nã€ç›¸å…³ä¸Šä¸‹æ–‡ã€‘\n" + "\n\n".join(compressed_context[:3]) + f"\n\n{question_part}"

        print(f"   æç¤ºè¯å·²å‹ç¼©: {len(prompt.split())} -> {len(compressed_prompt.split())} è¯")

        return compressed_prompt

    def _call_api(self, prompt: str) -> Union[str, Dict]:
        """
        è°ƒç”¨APIç”Ÿæˆç­”æ¡ˆ

        Args:
            prompt: æç¤ºè¯

        Returns:
            APIå“åº”
        """
        if not OPENAI_AVAILABLE:
            # æ¨¡æ‹Ÿå“åº”ï¼ˆç”¨äºæµ‹è¯•ï¼‰
            return "è¿™æ˜¯æ¨¡æ‹Ÿçš„AIå›ç­”ã€‚åœ¨å®é™…éƒ¨ç½²ä¸­ï¼Œéœ€è¦å®‰è£…openaiåº“å¹¶é…ç½®æœ‰æ•ˆçš„APIå¯†é’¥ã€‚"

        try:
            response = openai.ChatCompletion.create(
                model=self.model_name,
                messages=[
                    {"role": "system", "content": "ä½ æ˜¯ä¸“ä¸šçš„å›½é™…æ°‘èˆªç»„ç»‡é™„ä»¶14ä¸“å®¶ã€‚"},
                    {"role": "user", "content": prompt}
                ],
                temperature=self.config.get('temperature', 0.3),
                max_tokens=self.config.get('max_tokens', 1500),
                timeout=30
            )

            return response

        except Exception as e:
            print(f"âŒ APIè°ƒç”¨å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼ŒAIæœåŠ¡æš‚æ—¶ä¸å¯ç”¨ã€‚é”™è¯¯: {str(e)}"

    def _estimate_confidence(self, answer: str, context_parts: List[str]) -> float:
        """
        ä¼°è®¡ç­”æ¡ˆç½®ä¿¡åº¦

        Args:
            answer: ç”Ÿæˆçš„ç­”æ¡ˆ
            context_parts: ä¸Šä¸‹æ–‡æ–‡æœ¬åˆ—è¡¨

        Returns:
            ç½®ä¿¡åº¦åˆ†æ•° (0.0-1.0)
        """
        confidence = 0.8  # åŸºç¡€ç½®ä¿¡åº¦

        # æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦åŒ…å«ä¸ç¡®å®šè¯æ±‡
        uncertainty_words = ['å¯èƒ½', 'ä¹Ÿè®¸', 'å¤§æ¦‚', 'ä¸ç¡®å®š', 'æ— æ³•ç¡®è®¤', 'ä¸æ¸…æ¥š']
        if any(word in answer for word in uncertainty_words):
            confidence *= 0.7

        # æ£€æŸ¥ç­”æ¡ˆæ˜¯å¦æ˜ç¡®æ‹’ç»
        if 'æ— æ³•å›ç­”' in answer or 'æ²¡æœ‰ç›¸å…³ä¿¡æ¯' in answer:
            confidence = 0.3

        # æ£€æŸ¥æ˜¯å¦åŒ…å«å¼•ç”¨
        if 'ã€æ¥æº' in answer:
            confidence *= 1.1  # æœ‰å¼•ç”¨å¢åŠ ç½®ä¿¡åº¦

        # æ£€æŸ¥ç­”æ¡ˆé•¿åº¦
        if len(answer) < 50:
            confidence *= 0.8  # è¿‡çŸ­ç­”æ¡ˆå¯èƒ½ä¸å®Œæ•´

        return min(max(confidence, 0.0), 1.0)  # é™åˆ¶åœ¨0-1ä¹‹é—´

# ==================== è¯„ä¼°å™¨ ====================

class QAEvaluator:
    """QAç³»ç»Ÿè¯„ä¼°å™¨"""

    def __init__(self, document_chunks: List[DocumentChunk]):
        self.document_chunks = document_chunks
        self.interactions = []

    def record_interaction(self, question: str, response: Dict):
        """
        è®°å½•äº¤äº’ä¿¡æ¯

        Args:
            question: é—®é¢˜
            response: å“åº”
        """
        self.interactions.append({
            'question': question,
            'response': response,
            'timestamp': datetime.now()
        })

    def evaluate_accuracy(self, actual_answer: str, expected_answer: str) -> bool:
        """
        è¯„ä¼°ç­”æ¡ˆå‡†ç¡®æ€§

        Args:
            actual_answer: å®é™…ç­”æ¡ˆ
            expected_answer: æœŸæœ›ç­”æ¡ˆ

        Returns:
            æ˜¯å¦å‡†ç¡®
        """
        # ç®€å•å­—ç¬¦ä¸²åŒ¹é…ï¼ˆå¯æ‰©å±•ä¸ºæ›´å¤æ‚çš„NLPè¯„ä¼°ï¼‰
        actual_lower = actual_answer.lower()
        expected_lower = expected_answer.lower()

        # æ£€æŸ¥å…³é”®æœ¯è¯­æ˜¯å¦åŒ¹é…
        if expected_answer:
            expected_terms = re.findall(r'[\u4e00-\u9fa5]{2,6}|[A-Z]{2,}', expected_answer)
            matched_terms = 0

            for term in expected_terms:
                if term.lower() in actual_lower:
                    matched_terms += 1

            accuracy_ratio = matched_terms / len(expected_terms) if expected_terms else 0

            return accuracy_ratio > 0.6  # 60%çš„æœ¯è¯­åŒ¹é…å³è§†ä¸ºæ­£ç¡®

        return False  # æ²¡æœ‰æœŸæœ›ç­”æ¡ˆï¼Œæ— æ³•è¯„ä¼°

    def evaluate_citations(self, actual_citations: List[Dict], expected_citations: List[str]) -> Dict:
        """
        è¯„ä¼°å¼•ç”¨è´¨é‡

        Args:
            actual_citations: å®é™…å¼•ç”¨
            expected_citations: æœŸæœ›å¼•ç”¨ï¼ˆå…³é”®è¯åˆ—è¡¨ï¼‰

        Returns:
            å¼•ç”¨è¯„ä¼°æŒ‡æ ‡
        """
        if not expected_citations:
            return {'precision': 1.0, 'recall': 1.0, 'f1': 1.0, 'correct': 0, 'total_expected': 0}

        # æå–å®é™…å¼•ç”¨ä¸­çš„æ–‡æœ¬
        actual_texts = []
        for citation in actual_citations:
            if 'text' in citation:
                actual_texts.append(citation['text'])

        # è®¡ç®—åŒ¹é…æƒ…å†µ
        matched_citations = 0

        for expected in expected_citations:
            for actual in actual_texts:
                if expected.lower() in actual.lower():
                    matched_citations += 1
                    break

        precision = matched_citations / len(actual_citations) if actual_citations else 0
        recall = matched_citations / len(expected_citations) if expected_citations else 0

        f1 = 2 * precision * recall / (precision + recall) if (precision + recall) > 0 else 0

        return {
            'precision': precision,
            'recall': recall,
            'f1': f1,
            'correct': matched_citations,
            'total_expected': len(expected_citations)
        }

    def detect_hallucination(self, answer: str, citations: List[Dict]) -> bool:
        """
        æ£€æµ‹å¹»è§‰ï¼ˆç­”æ¡ˆä¸­çš„ä¿¡æ¯æ— æ³•è¢«å¼•ç”¨æ”¯æŒï¼‰

        Args:
            answer: ç­”æ¡ˆæ–‡æœ¬
            citations: å¼•ç”¨åˆ—è¡¨

        Returns:
            æ˜¯å¦å­˜åœ¨å¹»è§‰
        """
        if not citations:
            # æ²¡æœ‰å¼•ç”¨ï¼Œä½†ç­”æ¡ˆå£°ç§°æœ‰ç‰¹å®šä¿¡æ¯ï¼Œå¯èƒ½ä¸ºå¹»è§‰
            specific_claims = ['å¿…é¡»', 'åº”', 'ä¸å¾—', 'ç¦æ­¢', 'è¦æ±‚', 'æ ‡å‡†']
            if any(claim in answer for claim in specific_claims) and len(answer) > 100:
                return True
            return False

        # æ£€æŸ¥ç­”æ¡ˆä¸­çš„å…·ä½“æ•°æ®æ˜¯å¦åœ¨å¼•ç”¨ä¸­
        # è¿™é‡Œå®ç°ç®€å•çš„æ£€æŸ¥é€»è¾‘
        citation_texts = " ".join([c.get('text', '') for c in citations])

        # æå–ç­”æ¡ˆä¸­çš„æ•°å­—å’Œä¸“æœ‰åè¯
        numbers = re.findall(r'\d+\.?\d*', answer)
        terms = re.findall(r'[A-Z]{2,}[\d]*|[\u4e00-\u9fa5]{2,6}', answer)

        # æ£€æŸ¥è¿™äº›å…ƒç´ æ˜¯å¦åœ¨å¼•ç”¨ä¸­å‡ºç°
        missing_elements = 0

        for num in numbers[:5]:  # æ£€æŸ¥å‰5ä¸ªæ•°å­—
            if num not in citation_texts:
                missing_elements += 1

        for term in terms[:10]:  # æ£€æŸ¥å‰10ä¸ªæœ¯è¯­
            if len(term) > 2 and term not in citation_texts:
                missing_elements += 1

        # å¦‚æœç¼ºå¤±å…ƒç´ æ¯”ä¾‹è¿‡é«˜ï¼Œå¯èƒ½å­˜åœ¨å¹»è§‰
        total_elements = min(5, len(numbers)) + min(10, len(terms))
        hallucination_ratio = missing_elements / total_elements if total_elements > 0 else 0

        return hallucination_ratio > 0.5  # è¶…è¿‡50%çš„å…ƒç´ æœªåœ¨å¼•ç”¨ä¸­å‡ºç°

# ==================== ä½¿ç”¨ç¤ºä¾‹å’Œä¸»å‡½æ•° ====================

def main_demo():
    """
    ä¸»æ¼”ç¤ºå‡½æ•°ï¼šå±•ç¤ºç³»ç»ŸåŠŸèƒ½
    """
    print("="*70)
    print("å›½é™…æ°‘èˆªç»„ç»‡é™„ä»¶14ç¬¬Iå· - å¢å¼ºç‰ˆé—®ç­”ç³»ç»Ÿ")
    print("ç‰ˆæœ¬: 2.1 (åŒ…å«ç« èŠ‚ç›®å½•æç¤º)")
    print("="*70)

    # é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆè¯·ä¿®æ”¹ä¸ºå®é™…è·¯å¾„ï¼‰
    manual_path = input("è¯·è¾“å…¥æ‰‹å†Œæ–‡ä»¶è·¯å¾„ (ç›´æ¥å›è½¦è·³è¿‡ä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®): ").strip()

    if not manual_path:
        print("âš ï¸  æœªæä¾›æ‰‹å†Œè·¯å¾„ï¼Œå°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
        manual_path = "æ¨¡æ‹Ÿè·¯å¾„"

    # åˆå§‹åŒ–ç³»ç»Ÿ
    qa_system = Attachment14EnhancedQA(
        manual_path=manual_path,
        use_embedding=False,  # ä½¿ç”¨å…³é”®è¯æ£€ç´¢ï¼ˆé¿å…ä¾èµ–å¤–éƒ¨åº“ï¼‰
        show_toc=True
    )

    # æ¼”ç¤ºç« èŠ‚ç›®å½•åŠŸèƒ½
    print("\n" + "="*70)
    print("æ¼”ç¤º1: ç« èŠ‚ç›®å½•åŠŸèƒ½")
    print("="*70)

    # è·å–ç« èŠ‚ç›®å½•
    toc = qa_system.get_toc(detail_level=2)
    print(toc[:1000] + "..." if len(toc) > 1000 else toc)

    # æ¼”ç¤ºé—®ç­”åŠŸèƒ½
    print("\n" + "="*70)
    print("æ¼”ç¤º2: æ™ºèƒ½é—®ç­”åŠŸèƒ½")
    print("="*70)

    test_questions = [
        "ä»€ä¹ˆæ˜¯è·‘é“ç«¯å®‰å…¨åŒºï¼Ÿ",
        "PCNæ˜¯ä»€ä¹ˆæ„æ€ï¼Ÿ",
        "ç›®å½•",  # æµ‹è¯•ç« èŠ‚ç›®å½•æŸ¥è¯¢
        "ç¬¬3ç« è®²äº†ä»€ä¹ˆï¼Ÿ",
        "è·‘é“å®½åº¦æœ‰å“ªäº›è¦æ±‚ï¼Ÿ"
    ]

    for i, question in enumerate(test_questions, 1):
        print(f"\n[{i}] é—®: {question}")
        response = qa_system.ask(question, session_id="demo_session")

        print(f"ç­”: {response['answer'][:300]}...")

        if response.get('chapter_suggestions'):
            print(f"ğŸ“š ç« èŠ‚å»ºè®®:")
            for suggestion in response['chapter_suggestions']:
                print(f"   â€¢ {suggestion}")

        if response.get('citations'):
            print(f"ğŸ“– å¼•ç”¨æ¥æº: {len(response['citations'])} ä¸ª")

    # æ¼”ç¤ºå¤šè½®å¯¹è¯
    print("\n" + "="*70)
    print("æ¼”ç¤º3: å¤šè½®å¯¹è¯åŠŸèƒ½")
    print("="*70)

    multi_session = "multi_turn_demo"

    questions = [
        "è·‘é“ç«¯å®‰å…¨åŒºçš„ä½œç”¨æ˜¯ä»€ä¹ˆï¼Ÿ",
        "å®ƒçš„æœ€å°å°ºå¯¸æ˜¯å¤šå°‘ï¼Ÿ",
        "å¦‚æœå®‰è£…äº†æ‹¦é˜»ç³»ç»Ÿå‘¢ï¼Ÿ"
    ]

    for i, q in enumerate(questions, 1):
        print(f"\nç¬¬{i}è½®é—®: {q}")
        response = qa_system.ask(q, session_id=multi_session, use_history=True)
        print(f"ç­”: {response['answer'][:200]}... (ç½®ä¿¡åº¦: {response['confidence']:.2%})")

    # æŸ¥çœ‹å¯¹è¯å†å²
    print("\nå¯¹è¯å†å²:")
    history = qa_system.get_conversation_history(multi_session)
    for i, turn in enumerate(history, 1):
        role_icon = "ğŸ‘¤" if turn['role'] == 'user' else "ğŸ¤–"
        print(f"  {i}. {role_icon} [{turn['time']}] {turn['content'][:80]}...")

    # ç³»ç»Ÿç»Ÿè®¡
    print("\n" + "="*70)
    print("ç³»ç»Ÿç»Ÿè®¡ä¿¡æ¯")
    print("="*70)

    stats = qa_system.get_system_stats()
    for key, value in stats.items():
        print(f"  {key}: {value}")

    print("\n" + "="*70)
    print("âœ… æ¼”ç¤ºå®Œæˆ!")
    print("="*70)

def interactive_mode():
    """
    äº¤äº’æ¨¡å¼ï¼šå‘½ä»¤è¡Œäº¤äº’é—®ç­”
    """
    print("="*70)
    print("é™„ä»¶14æ‰‹å†Œ - äº¤äº’å¼é—®ç­”æ¨¡å¼ (å¢å¼ºç‰ˆ)")
    print("="*70)
    print("ğŸ“š å¯ç”¨å‘½ä»¤:")
    print("  'ç›®å½•' æˆ– 'toc' - æŸ¥çœ‹ç« èŠ‚ç›®å½•")
    print("  'ç¬¬Xç« ' - æŸ¥çœ‹å…·ä½“ç« èŠ‚å†…å®¹")
    print("  'å†å²' - æŸ¥çœ‹å¯¹è¯å†å²")
    print("  'ç»Ÿè®¡' - æŸ¥çœ‹ç³»ç»Ÿç»Ÿè®¡")
    print("  'æ¸…é™¤' - æ¸…é™¤å¯¹è¯å†å²")
    print("  'é€€å‡º' æˆ– 'quit' - ç»“æŸå¯¹è¯")
    print("="*70)

    # åˆå§‹åŒ–ç³»ç»Ÿ
    manual_path = input("è¯·è¾“å…¥æ‰‹å†Œæ–‡ä»¶è·¯å¾„ (ç›´æ¥å›è½¦ä½¿ç”¨é»˜è®¤è·¯å¾„): ").strip()

    if not manual_path:
        # è¿™é‡Œåº”è¯¥è®¾ç½®ä¸€ä¸ªé»˜è®¤è·¯å¾„
        manual_path = "é™„ä»¶14æ‰‹å†Œè·¯å¾„"
        print(f"ä½¿ç”¨é»˜è®¤è·¯å¾„: {manual_path}")

    try:
        qa_system = Attachment14EnhancedQA(
            manual_path=manual_path,
            use_embedding=False,  # ä½¿ç”¨å…³é”®è¯æ£€ç´¢
            show_toc=True
        )
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        print("âš ï¸  å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼ç»§ç»­...")
        # åˆ›å»ºæ¨¡æ‹Ÿç³»ç»Ÿ
        qa_system = type('obj', (object,), {
            'ask': lambda self, q, **kwargs: {
                'answer': f"æ¨¡æ‹Ÿå›ç­”: {q}",
                'citations': [],
                'confidence': 0.8,
                'chapter_suggestions': ['ğŸ“˜ ç¬¬1ç«  æ€»åˆ™', 'ğŸ“˜ ç¬¬3ç«  ç‰©ç†ç‰¹æ€§'],
                'response_time': 0.5
            },
            'get_toc': lambda self, detail_level=2: "ğŸ“– æ¨¡æ‹Ÿç« èŠ‚ç›®å½•\n1. ç¬¬1ç«  æ€»åˆ™\n2. ç¬¬2ç«  æœºåœºæ•°æ®\n3. ç¬¬3ç«  ç‰©ç†ç‰¹æ€§",
            'get_conversation_history': lambda self, session_id="default": [],
            'get_system_stats': lambda self: {'total_queries': 0, 'success_rate': 0},
            'clear_conversation': lambda self, session_id="default": print("ğŸ—‘ï¸  å¯¹è¯å†å²å·²æ¸…é™¤")
        })()

    session_id = "interactive_session"

    while True:
        try:
            print("\n" + "-"*50)
            question = input("ğŸ’­ è¯·è¾“å…¥é—®é¢˜æˆ–å‘½ä»¤: ").strip()

            if not question:
                continue

            # æ£€æŸ¥å‘½ä»¤
            question_lower = question.lower()

            if question_lower in ['quit', 'é€€å‡º', 'exit']:
                print("ğŸ‘‹ æ„Ÿè°¢ä½¿ç”¨ï¼Œå†è§ï¼")
                break
            elif question_lower in ['clear', 'æ¸…é™¤', 'æ¸…ç©º']:
                qa_system.clear_conversation(session_id)
                print("ğŸ—‘ï¸  å¯¹è¯å†å²å·²æ¸…é™¤")
                continue
            elif question_lower in ['history', 'å†å²', 'å¯¹è¯å†å²']:
                history = qa_system.get_conversation_history(session_id)
                if not history:
                    print("ğŸ“ æ— å¯¹è¯å†å²")
                else:
                    print("\nğŸ“ å¯¹è¯å†å²:")
                    for i, turn in enumerate(history, 1):
                        role_icon = "ğŸ‘¤" if turn['role'] == 'user' else "ğŸ¤–"
                        confidence_str = f" ({turn['confidence']:.0%})" if 'confidence' in turn else ""
                        print(f"  {i}. {role_icon}{confidence_str} {turn['content'][:80]}...")
                continue
            elif question_lower in ['stats', 'ç»Ÿè®¡', 'çŠ¶æ€']:
                stats = qa_system.get_system_stats()
                print("\nğŸ“Š ç³»ç»Ÿç»Ÿè®¡:")
                for key, value in stats.items():
                    print(f"  {key}: {value}")
                continue
            elif question_lower in ['toc', 'ç›®å½•', 'ç« èŠ‚ç›®å½•']:
                detail_level = 2
                if 'è¯¦ç»†' in question:
                    detail_level = 4
                elif 'ç®€è¦' in question:
                    detail_level = 1

                toc = qa_system.get_toc(detail_level=detail_level)
                print(f"\n{toc}")
                continue

            # å¤„ç†é—®é¢˜
            print("â³ æ­£åœ¨æœç´¢å’Œç”Ÿæˆç­”æ¡ˆ...")
            response = qa_system.ask(question, session_id=session_id)

            print(f"\n{'='*60}")
            print(f"âœ… ç­”æ¡ˆ (ç½®ä¿¡åº¦: {response['confidence']:.2%}):")
            print(f"{response['answer']}")

            # æ˜¾ç¤ºç« èŠ‚å»ºè®®ï¼ˆå¦‚æœæœ‰ï¼‰
            if response.get('chapter_suggestions'):
                print(f"\nğŸ“š ç›¸å…³ç« èŠ‚å»ºè®®:")
                for suggestion in response['chapter_suggestions']:
                    print(f"  â€¢ {suggestion}")

            # æ˜¾ç¤ºå¼•ç”¨ï¼ˆå¦‚æœæœ‰ï¼‰
            if response.get('citations'):
                print(f"\nğŸ“– å¼•ç”¨æ¥æº ({len(response['citations'])} ä¸ª):")
                for i, citation in enumerate(response['citations'], 1):
                    chapter_info = citation.get('chapter_path', 'æœªçŸ¥ç« èŠ‚')
                    print(f"  {i}. ã€{citation['chunk_id']}ã€‘{chapter_info}")
                    print(f"     åŸæ–‡: {citation['text'][:100]}...")

            # æ˜¾ç¤ºå“åº”æ—¶é—´
            print(f"\nâ±ï¸  å“åº”æ—¶é—´: {response['response_time']:.2f}ç§’")

            # æç¤ºç”¨æˆ·å¯ä»¥ä½¿ç”¨ç« èŠ‚ç›®å½•åŠŸèƒ½
            if 'æ— æ³•æ‰¾åˆ°' in response['answer'] or response['confidence'] < 0.5:
                print(f"\nğŸ’¡ æç¤º: å¯ä»¥å°è¯•è¾“å…¥'ç›®å½•'æŸ¥çœ‹æ‰‹å†Œç»“æ„ï¼Œæˆ–è¾“å…¥'ç¬¬Xç« 'æŸ¥çœ‹å…·ä½“å†…å®¹")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œé€€å‡ºç³»ç»Ÿ")
            break
        except Exception as e:
            print(f"âŒ å¤„ç†é—®é¢˜æ—¶å‡ºé”™: {e}")
            print("ğŸ’¡ å»ºè®®æ£€æŸ¥æ‰‹å†Œæ–‡ä»¶è·¯å¾„æ˜¯å¦æ­£ç¡®ï¼Œæˆ–ä½¿ç”¨æ›´ç®€å•çš„é—®é¢˜é‡è¯•")

# ==================== å¿«é€Ÿå¯åŠ¨å‡½æ•° ====================

def quick_start():
    """
    å¿«é€Ÿå¯åŠ¨å‡½æ•°ï¼šç®€åŒ–ç³»ç»Ÿå¯åŠ¨æµç¨‹
    """
    print("ğŸš€ é™„ä»¶14é—®ç­”ç³»ç»Ÿ - å¿«é€Ÿå¯åŠ¨")
    print("="*50)

    print("è¯·é€‰æ‹©æ¨¡å¼:")
    print("1. äº¤äº’æ¨¡å¼ (å‘½ä»¤è¡Œé—®ç­”)")
    print("2. æ¼”ç¤ºæ¨¡å¼ (æŸ¥çœ‹ç³»ç»ŸåŠŸèƒ½)")
    print("3. é€€å‡º")

    choice = input("\nè¯·é€‰æ‹© (1-3): ").strip()

    if choice == "1":
        interactive_mode()
    elif choice == "2":
        main_demo()
    elif choice == "3":
        print("ğŸ‘‹ å†è§!")
    else:
        print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·é‡æ–°è¿è¡Œç¨‹åº")

if __name__ == "__main__":
    # ç›´æ¥è¿è¡Œäº¤äº’æ¨¡å¼
    interactive_mode()

    # æˆ–è€…è¿è¡Œå¿«é€Ÿå¯åŠ¨èœå•
    # quick_start()